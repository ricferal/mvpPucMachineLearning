{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab704d84",
   "metadata": {},
   "source": [
    "# MVP - Processo Seletivo de Pós-Graduação PUC-Rio\n",
    "## Aplicação de Machine Learning, Analytics Descritiva/Preditiva e Advanced Analytics\n",
    "\n",
    "### Objetivo do Projeto\n",
    "Este notebook demonstra a aplicação das três disciplinas em um cenário real de processo seletivo para pós-graduação (mestrado e doutorado) na PUC-Rio. O objetivo é desenvolver um modelo preditivo que determine a aprovação ou reprovação de candidatos com base em critérios pré-estabelecidos.\n",
    "\n",
    "### Disciplinas Aplicadas:\n",
    "- **Machine Learning**: Desenvolvimento de modelos preditivos\n",
    "- **Analytics Descritiva e Preditiva**: Análise exploratória e modelagem preditiva\n",
    "- **Advanced Analytics**: Avaliação avançada de modelos e insights estratégicos\n",
    "\n",
    "### Dataset Simulado\n",
    "Utilizaremos um dataset simulado contendo informações de candidatos ao processo seletivo, incluindo:\n",
    "- Dados acadêmicos (notas, formação)\n",
    "- Experiência profissional\n",
    "- Publicações e pesquisa\n",
    "- Critérios específicos do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb2d547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Advanced Analytics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import plot_tree\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c80a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset criado com 1000 candidatos\n",
      "Colunas: ['id_candidato', 'programa', 'area_conhecimento', 'nota_graduacao', 'nota_pos_graduacao', 'anos_experiencia', 'num_publicacoes', 'nota_prova_especifica', 'nota_entrevista', 'proficiencia_ingles', 'tem_orientador', 'renda_familiar', 'idade']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_candidato</th>\n",
       "      <th>programa</th>\n",
       "      <th>area_conhecimento</th>\n",
       "      <th>nota_graduacao</th>\n",
       "      <th>nota_pos_graduacao</th>\n",
       "      <th>anos_experiencia</th>\n",
       "      <th>num_publicacoes</th>\n",
       "      <th>nota_prova_especifica</th>\n",
       "      <th>nota_entrevista</th>\n",
       "      <th>proficiencia_ingles</th>\n",
       "      <th>tem_orientador</th>\n",
       "      <th>renda_familiar</th>\n",
       "      <th>idade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Engenharia</td>\n",
       "      <td>7.146421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.743621</td>\n",
       "      <td>1</td>\n",
       "      <td>9.772072</td>\n",
       "      <td>7.955994</td>\n",
       "      <td>Avançado</td>\n",
       "      <td>0</td>\n",
       "      <td>5559.039430</td>\n",
       "      <td>21.459751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Ciências Exatas</td>\n",
       "      <td>7.207744</td>\n",
       "      <td>9.189614</td>\n",
       "      <td>2.162837</td>\n",
       "      <td>1</td>\n",
       "      <td>8.116012</td>\n",
       "      <td>7.659488</td>\n",
       "      <td>Intermediário</td>\n",
       "      <td>0</td>\n",
       "      <td>1576.148612</td>\n",
       "      <td>23.902570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Biológicas</td>\n",
       "      <td>7.928225</td>\n",
       "      <td>7.931707</td>\n",
       "      <td>1.019810</td>\n",
       "      <td>3</td>\n",
       "      <td>7.849291</td>\n",
       "      <td>7.985681</td>\n",
       "      <td>Básico</td>\n",
       "      <td>0</td>\n",
       "      <td>3751.823653</td>\n",
       "      <td>23.757782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Humanas</td>\n",
       "      <td>8.640839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>2</td>\n",
       "      <td>5.797343</td>\n",
       "      <td>7.582492</td>\n",
       "      <td>Avançado</td>\n",
       "      <td>1</td>\n",
       "      <td>7063.124727</td>\n",
       "      <td>23.878365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Biológicas</td>\n",
       "      <td>9.296302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056961</td>\n",
       "      <td>1</td>\n",
       "      <td>6.263272</td>\n",
       "      <td>5.969357</td>\n",
       "      <td>Básico</td>\n",
       "      <td>1</td>\n",
       "      <td>1809.262631</td>\n",
       "      <td>31.748679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_candidato   programa area_conhecimento  nota_graduacao  \\\n",
       "0             1   Mestrado        Engenharia        7.146421   \n",
       "1             2  Doutorado   Ciências Exatas        7.207744   \n",
       "2             3  Doutorado        Biológicas        7.928225   \n",
       "3             4   Mestrado           Humanas        8.640839   \n",
       "4             5   Mestrado        Biológicas        9.296302   \n",
       "\n",
       "   nota_pos_graduacao  anos_experiencia  num_publicacoes  \\\n",
       "0                 NaN          2.743621                1   \n",
       "1            9.189614          2.162837                1   \n",
       "2            7.931707          1.019810                3   \n",
       "3                 NaN          0.019456                2   \n",
       "4                 NaN          2.056961                1   \n",
       "\n",
       "   nota_prova_especifica  nota_entrevista proficiencia_ingles  tem_orientador  \\\n",
       "0               9.772072         7.955994            Avançado               0   \n",
       "1               8.116012         7.659488       Intermediário               0   \n",
       "2               7.849291         7.985681              Básico               0   \n",
       "3               5.797343         7.582492            Avançado               1   \n",
       "4               6.263272         5.969357              Básico               1   \n",
       "\n",
       "   renda_familiar      idade  \n",
       "0     5559.039430  21.459751  \n",
       "1     1576.148612  23.902570  \n",
       "2     3751.823653  23.757782  \n",
       "3     7063.124727  23.878365  \n",
       "4     1809.262631  31.748679  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação do Dataset Simulado - Processo Seletivo PUC-Rio\n",
    "np.random.seed(42)\n",
    "n_candidates = 1000\n",
    "\n",
    "# Gerando dados simulados\n",
    "data = {\n",
    "    'id_candidato': range(1, n_candidates + 1),\n",
    "    'programa': np.random.choice(['Mestrado', 'Doutorado'], n_candidates, p=[0.7, 0.3]),\n",
    "    'area_conhecimento': np.random.choice(['Engenharia', 'Ciências Exatas', 'Humanas', 'Biológicas'], \n",
    "                                        n_candidates, p=[0.3, 0.25, 0.25, 0.2]),\n",
    "    'nota_graduacao': np.random.normal(8.2, 1.2, n_candidates),\n",
    "    'nota_pos_graduacao': np.random.normal(8.8, 1.0, n_candidates),\n",
    "    'anos_experiencia': np.random.exponential(3, n_candidates),\n",
    "    'num_publicacoes': np.random.poisson(2, n_candidates),\n",
    "    'nota_prova_especifica': np.random.normal(7.5, 1.5, n_candidates),\n",
    "    'nota_entrevista': np.random.normal(8.0, 1.0, n_candidates),\n",
    "    'proficiencia_ingles': np.random.choice(['Básico', 'Intermediário', 'Avançado'], \n",
    "                                          n_candidates, p=[0.3, 0.4, 0.3]),\n",
    "    'tem_orientador': np.random.choice([0, 1], n_candidates, p=[0.4, 0.6]),\n",
    "    'renda_familiar': np.random.lognormal(8, 0.5, n_candidates),\n",
    "    'idade': np.random.normal(26, 4, n_candidates)\n",
    "}\n",
    "\n",
    "# Criando DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ajustando alguns valores para realismo\n",
    "df['nota_graduacao'] = np.clip(df['nota_graduacao'], 5.0, 10.0)\n",
    "df['nota_pos_graduacao'] = np.where(df['programa'] == 'Doutorado', \n",
    "                                   np.clip(df['nota_pos_graduacao'], 6.0, 10.0), \n",
    "                                   np.nan)\n",
    "df['anos_experiencia'] = np.clip(df['anos_experiencia'], 0, 15)\n",
    "df['num_publicacoes'] = np.where(df['programa'] == 'Doutorado', \n",
    "                                df['num_publicacoes'] + np.random.poisson(1, n_candidates), \n",
    "                                df['num_publicacoes'])\n",
    "df['nota_prova_especifica'] = np.clip(df['nota_prova_especifica'], 0, 10)\n",
    "df['nota_entrevista'] = np.clip(df['nota_entrevista'], 0, 10)\n",
    "df['idade'] = np.clip(df['idade'], 20, 45)\n",
    "\n",
    "print(f\"Dataset criado com {len(df)} candidatos\")\n",
    "print(f\"Colunas: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20683965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPLORAÇÃO INICIAL DO DATASET ===\n",
      "Total de candidatos: 1000\n",
      "Aprovados: 790 (79.0%)\n",
      "Reprovados: 210 (21.0%)\n",
      "\n",
      "=== DISTRIBUIÇÃO POR PROGRAMA ===\n",
      "aprovado     0    1\n",
      "programa           \n",
      "Doutorado   34  254\n",
      "Mestrado   176  536\n",
      "\n",
      "=== INFORMAÇÕES GERAIS ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id_candidato           1000 non-null   int64  \n",
      " 1   programa               1000 non-null   object \n",
      " 2   area_conhecimento      1000 non-null   object \n",
      " 3   nota_graduacao         1000 non-null   float64\n",
      " 4   nota_pos_graduacao     288 non-null    float64\n",
      " 5   anos_experiencia       1000 non-null   float64\n",
      " 6   num_publicacoes        1000 non-null   int32  \n",
      " 7   nota_prova_especifica  1000 non-null   float64\n",
      " 8   nota_entrevista        1000 non-null   float64\n",
      " 9   proficiencia_ingles    1000 non-null   object \n",
      " 10  tem_orientador         1000 non-null   int64  \n",
      " 11  renda_familiar         1000 non-null   float64\n",
      " 12  idade                  1000 non-null   float64\n",
      " 13  aprovado               1000 non-null   int64  \n",
      "dtypes: float64(7), int32(1), int64(3), object(3)\n",
      "memory usage: 105.6+ KB\n",
      "None\n",
      "\n",
      "=== ESTATÍSTICAS DESCRITIVAS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_candidato</th>\n",
       "      <th>nota_graduacao</th>\n",
       "      <th>nota_pos_graduacao</th>\n",
       "      <th>anos_experiencia</th>\n",
       "      <th>num_publicacoes</th>\n",
       "      <th>nota_prova_especifica</th>\n",
       "      <th>nota_entrevista</th>\n",
       "      <th>tem_orientador</th>\n",
       "      <th>renda_familiar</th>\n",
       "      <th>idade</th>\n",
       "      <th>aprovado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>8.182053</td>\n",
       "      <td>8.699546</td>\n",
       "      <td>2.979821</td>\n",
       "      <td>2.20300</td>\n",
       "      <td>7.451288</td>\n",
       "      <td>7.990369</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>3334.770088</td>\n",
       "      <td>26.139954</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>1.099584</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>2.907030</td>\n",
       "      <td>1.48728</td>\n",
       "      <td>1.469298</td>\n",
       "      <td>1.009288</td>\n",
       "      <td>0.491138</td>\n",
       "      <td>1780.272005</td>\n",
       "      <td>3.830589</td>\n",
       "      <td>0.407512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.478674</td>\n",
       "      <td>4.883347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>529.997651</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.750000</td>\n",
       "      <td>7.424133</td>\n",
       "      <td>8.082758</td>\n",
       "      <td>0.889294</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.453870</td>\n",
       "      <td>7.311743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2075.697201</td>\n",
       "      <td>23.406021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>8.201040</td>\n",
       "      <td>8.707071</td>\n",
       "      <td>1.983081</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.451237</td>\n",
       "      <td>8.009141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2941.179562</td>\n",
       "      <td>26.062398</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750.250000</td>\n",
       "      <td>9.007175</td>\n",
       "      <td>9.454600</td>\n",
       "      <td>4.161469</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.522133</td>\n",
       "      <td>8.704994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4067.676276</td>\n",
       "      <td>28.860953</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12816.855065</td>\n",
       "      <td>38.413538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_candidato  nota_graduacao  nota_pos_graduacao  anos_experiencia  \\\n",
       "count   1000.000000     1000.000000          288.000000       1000.000000   \n",
       "mean     500.500000        8.182053            8.699546          2.979821   \n",
       "std      288.819436        1.099584            0.933559          2.907030   \n",
       "min        1.000000        5.000000            6.000000          0.000681   \n",
       "25%      250.750000        7.424133            8.082758          0.889294   \n",
       "50%      500.500000        8.201040            8.707071          1.983081   \n",
       "75%      750.250000        9.007175            9.454600          4.161469   \n",
       "max     1000.000000       10.000000           10.000000         15.000000   \n",
       "\n",
       "       num_publicacoes  nota_prova_especifica  nota_entrevista  \\\n",
       "count       1000.00000            1000.000000      1000.000000   \n",
       "mean           2.20300               7.451288         7.990369   \n",
       "std            1.48728               1.469298         1.009288   \n",
       "min            0.00000               2.478674         4.883347   \n",
       "25%            1.00000               6.453870         7.311743   \n",
       "50%            2.00000               7.451237         8.009141   \n",
       "75%            3.00000               8.522133         8.704994   \n",
       "max            8.00000              10.000000        10.000000   \n",
       "\n",
       "       tem_orientador  renda_familiar        idade     aprovado  \n",
       "count     1000.000000     1000.000000  1000.000000  1000.000000  \n",
       "mean         0.595000     3334.770088    26.139954     0.790000  \n",
       "std          0.491138     1780.272005     3.830589     0.407512  \n",
       "min          0.000000      529.997651    20.000000     0.000000  \n",
       "25%          0.000000     2075.697201    23.406021     1.000000  \n",
       "50%          1.000000     2941.179562    26.062398     1.000000  \n",
       "75%          1.000000     4067.676276    28.860953     1.000000  \n",
       "max          1.000000    12816.855065    38.413538     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando variável target baseada em critérios de aprovação\n",
    "def calcular_aprovacao(row):\n",
    "    \"\"\"\n",
    "    Critérios de aprovação baseados em regras do processo seletivo:\n",
    "    - Nota graduação >= 7.0\n",
    "    - Nota prova específica >= 6.0  \n",
    "    - Nota entrevista >= 7.0\n",
    "    - Para doutorado: nota pós-graduação >= 8.0 e publicações >= 1\n",
    "    - Bonus por experiência e orientador\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Critérios básicos\n",
    "    if row['nota_graduacao'] >= 7.0:\n",
    "        score += 2\n",
    "    if row['nota_prova_especifica'] >= 6.0:\n",
    "        score += 2\n",
    "    if row['nota_entrevista'] >= 7.0:\n",
    "        score += 2\n",
    "        \n",
    "    # Critérios específicos para doutorado\n",
    "    if row['programa'] == 'Doutorado':\n",
    "        if pd.notna(row['nota_pos_graduacao']) and row['nota_pos_graduacao'] >= 8.0:\n",
    "            score += 2\n",
    "        if row['num_publicacoes'] >= 1:\n",
    "            score += 1\n",
    "    \n",
    "    # Bonus\n",
    "    if row['anos_experiencia'] >= 2:\n",
    "        score += 1\n",
    "    if row['tem_orientador'] == 1:\n",
    "        score += 1\n",
    "    if row['proficiencia_ingles'] == 'Avançado':\n",
    "        score += 1\n",
    "        \n",
    "    # Aprovação se score >= 6 para mestrado ou >= 7 para doutorado\n",
    "    limite = 7 if row['programa'] == 'Doutorado' else 6\n",
    "    return 1 if score >= limite else 0\n",
    "\n",
    "# Aplicando função de aprovação\n",
    "df['aprovado'] = df.apply(calcular_aprovacao, axis=1)\n",
    "\n",
    "# Explorando o dataset\n",
    "print(\"=== EXPLORAÇÃO INICIAL DO DATASET ===\")\n",
    "print(f\"Total de candidatos: {len(df)}\")\n",
    "print(f\"Aprovados: {df['aprovado'].sum()} ({df['aprovado'].mean()*100:.1f}%)\")\n",
    "print(f\"Reprovados: {(df['aprovado']==0).sum()} ({(1-df['aprovado'].mean())*100:.1f}%)\")\n",
    "print(\"\\n=== DISTRIBUIÇÃO POR PROGRAMA ===\")\n",
    "print(df.groupby(['programa', 'aprovado']).size().unstack(fill_value=0))\n",
    "\n",
    "print(\"\\n=== INFORMAÇÕES GERAIS ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== ESTATÍSTICAS DESCRITIVAS ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde3a68",
   "metadata": {},
   "source": [
    "## 1. Analytics Descritiva - Análise Exploratória dos Dados (EDA)\n",
    "\n",
    "Nesta seção, aplicaremos técnicas de **Analytics Descritiva** para compreender os padrões nos dados do processo seletivo. Utilizaremos visualizações e estatísticas para identificar características dos candidatos aprovados vs. reprovados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALYTICS DESCRITIVA ===\n",
    "\n",
    "# 1. Distribuição da variável target\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Distribuição geral de aprovação\n",
    "df['aprovado'].value_counts().plot(kind='bar', ax=axes[0], color=['red', 'green'])\n",
    "axes[0].set_title('Distribuição de Aprovação Geral')\n",
    "axes[0].set_xlabel('Status')\n",
    "axes[0].set_ylabel('Número de Candidatos')\n",
    "axes[0].set_xticklabels(['Reprovado', 'Aprovado'], rotation=0)\n",
    "\n",
    "# Distribuição por programa\n",
    "df.groupby(['programa', 'aprovado']).size().unstack().plot(kind='bar', ax=axes[1], \n",
    "                                                          color=['red', 'green'])\n",
    "axes[1].set_title('Distribuição de Aprovação por Programa')\n",
    "axes[1].set_xlabel('Programa')\n",
    "axes[1].set_ylabel('Número de Candidatos')\n",
    "axes[1].legend(['Reprovado', 'Aprovado'])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Análise das notas por status de aprovação\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Nota graduação\n",
    "sns.boxplot(data=df, x='aprovado', y='nota_graduacao', ax=axes[0,0])\n",
    "axes[0,0].set_title('Distribuição da Nota de Graduação')\n",
    "axes[0,0].set_xticklabels(['Reprovado', 'Aprovado'])\n",
    "\n",
    "# Nota prova específica\n",
    "sns.boxplot(data=df, x='aprovado', y='nota_prova_especifica', ax=axes[0,1])\n",
    "axes[0,1].set_title('Distribuição da Nota da Prova Específica')\n",
    "axes[0,1].set_xticklabels(['Reprovado', 'Aprovado'])\n",
    "\n",
    "# Nota entrevista\n",
    "sns.boxplot(data=df, x='aprovado', y='nota_entrevista', ax=axes[1,0])\n",
    "axes[1,0].set_title('Distribuição da Nota da Entrevista')\n",
    "axes[1,0].set_xticklabels(['Reprovado', 'Aprovado'])\n",
    "\n",
    "# Anos de experiência\n",
    "sns.boxplot(data=df, x='aprovado', y='anos_experiencia', ax=axes[1,1])\n",
    "axes[1,1].set_title('Distribuição dos Anos de Experiência')\n",
    "axes[1,1].set_xticklabels(['Reprovado', 'Aprovado'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Matriz de correlação das variáveis numéricas\n",
    "numeric_cols = ['nota_graduacao', 'nota_pos_graduacao', 'anos_experiencia', \n",
    "                'num_publicacoes', 'nota_prova_especifica', 'nota_entrevista', \n",
    "                'tem_orientador', 'renda_familiar', 'idade', 'aprovado']\n",
    "\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Matriz de Correlação - Variáveis Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Análise das variáveis categóricas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Área de conhecimento\n",
    "area_approval = df.groupby('area_conhecimento')['aprovado'].mean().sort_values(ascending=False)\n",
    "area_approval.plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Taxa de Aprovação por Área de Conhecimento')\n",
    "axes[0].set_ylabel('Taxa de Aprovação')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Proficiência em inglês\n",
    "ingles_approval = df.groupby('proficiencia_ingles')['aprovado'].mean()\n",
    "ingles_approval.plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Taxa de Aprovação por Proficiência em Inglês')\n",
    "axes[1].set_ylabel('Taxa de Aprovação')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Tem orientador\n",
    "orientador_approval = df.groupby('tem_orientador')['aprovado'].mean()\n",
    "orientador_approval.plot(kind='bar', ax=axes[2], color='orange')\n",
    "axes[2].set_title('Taxa de Aprovação por Orientador')\n",
    "axes[2].set_ylabel('Taxa de Aprovação')\n",
    "axes[2].set_xticklabels(['Sem Orientador', 'Com Orientador'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Insights da análise descritiva\n",
    "print(\"=== INSIGHTS DA ANÁLISE DESCRITIVA ===\")\n",
    "print(f\"1. Taxa geral de aprovação: {df['aprovado'].mean()*100:.1f}%\")\n",
    "print(f\"2. Correlação mais forte com aprovação: {corr_matrix['aprovado'].abs().sort_values(ascending=False)[1:4].to_dict()}\")\n",
    "print(f\"3. Área com maior taxa de aprovação: {area_approval.index[0]} ({area_approval.iloc[0]*100:.1f}%)\")\n",
    "print(f\"4. Impacto de ter orientador: {orientador_approval[1]*100:.1f}% vs {orientador_approval[0]*100:.1f}%\")\n",
    "print(f\"5. Média das notas dos aprovados vs reprovados:\")\n",
    "for col in ['nota_graduacao', 'nota_prova_especifica', 'nota_entrevista']:\n",
    "    aprovados = df[df['aprovado']==1][col].mean()\n",
    "    reprovados = df[df['aprovado']==0][col].mean()\n",
    "    print(f\"   {col}: {aprovados:.2f} vs {reprovados:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc84e63",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados para Machine Learning\n",
    "\n",
    "Antes de aplicar os algoritmos de **Machine Learning**, precisamos preparar os dados:\n",
    "- Tratamento de valores faltantes\n",
    "- Codificação de variáveis categóricas\n",
    "- Normalização de features\n",
    "- Divisão em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREPARAÇÃO DOS DADOS ===\n",
    "\n",
    "# 1. Tratamento de valores faltantes\n",
    "print(\"Valores faltantes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Para nota_pos_graduacao (apenas para doutorado), vamos preencher com a mediana\n",
    "df['nota_pos_graduacao'] = df['nota_pos_graduacao'].fillna(\n",
    "    df[df['programa'] == 'Doutorado']['nota_pos_graduacao'].median()\n",
    ")\n",
    "\n",
    "# 2. Criando uma cópia para preparação\n",
    "df_ml = df.copy()\n",
    "\n",
    "# 3. Encoding das variáveis categóricas\n",
    "le_programa = LabelEncoder()\n",
    "df_ml['programa_encoded'] = le_programa.fit_transform(df_ml['programa'])\n",
    "\n",
    "le_area = LabelEncoder()\n",
    "df_ml['area_conhecimento_encoded'] = le_area.fit_transform(df_ml['area_conhecimento'])\n",
    "\n",
    "le_ingles = LabelEncoder()\n",
    "df_ml['proficiencia_ingles_encoded'] = le_ingles.fit_transform(df_ml['proficiencia_ingles'])\n",
    "\n",
    "# 4. Selecionando features para o modelo\n",
    "features = [\n",
    "    'programa_encoded', 'area_conhecimento_encoded', 'nota_graduacao', \n",
    "    'nota_pos_graduacao', 'anos_experiencia', 'num_publicacoes',\n",
    "    'nota_prova_especifica', 'nota_entrevista', 'proficiencia_ingles_encoded',\n",
    "    'tem_orientador', 'renda_familiar', 'idade'\n",
    "]\n",
    "\n",
    "X = df_ml[features]\n",
    "y = df_ml['aprovado']\n",
    "\n",
    "# 5. Divisão treino-teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 6. Normalização das features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nDataset preparado:\")\n",
    "print(f\"Features utilizadas: {len(features)}\")\n",
    "print(f\"Tamanho do treino: {X_train.shape}\")\n",
    "print(f\"Tamanho do teste: {X_test.shape}\")\n",
    "print(f\"Distribuição do target no treino: {np.bincount(y_train)}\")\n",
    "print(f\"Distribuição do target no teste: {np.bincount(y_test)}\")\n",
    "\n",
    "# Mostrando as features e seus tipos\n",
    "print(\"\\nFeatures selecionadas:\")\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"{i+1:2d}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8819da",
   "metadata": {},
   "source": [
    "## 3. Machine Learning e Analytics Preditiva\n",
    "\n",
    "Nesta seção, aplicaremos algoritmos de **Machine Learning** para criar modelos preditivos que determinem a aprovação dos candidatos. Testaremos diferentes algoritmos e compararemos seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7215fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MACHINE LEARNING E ANALYTICS PREDITIVA ===\n",
    "\n",
    "# 1. Definindo os modelos a serem testados\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 2. Treinamento e avaliação dos modelos\n",
    "results = {}\n",
    "model_objects = {}\n",
    "\n",
    "print(\"=== TREINAMENTO DOS MODELOS ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    \n",
    "    # Treinar modelo\n",
    "    if 'Logistic' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # Cross-validation\n",
    "    if 'Logistic' in name:\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    model_objects[name] = model\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "# 3. Comparação dos modelos\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n=== COMPARAÇÃO DOS MODELOS ===\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d54334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualização da comparação dos modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "results_df['accuracy'].plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Accuracy por Modelo')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# F1-Score\n",
    "results_df['f1_score'].plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "axes[0,1].set_title('F1-Score por Modelo')\n",
    "axes[0,1].set_ylabel('F1-Score')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# AUC\n",
    "results_df['auc'].plot(kind='bar', ax=axes[1,0], color='orange')\n",
    "axes[1,0].set_title('AUC por Modelo')\n",
    "axes[1,0].set_ylabel('AUC')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cross-validation scores\n",
    "results_df['cv_mean'].plot(kind='bar', ax=axes[1,1], color='pink', \n",
    "                          yerr=results_df['cv_std'])\n",
    "axes[1,1].set_title('Cross-Validation Score')\n",
    "axes[1,1].set_ylabel('CV Score')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Selecionando o melhor modelo\n",
    "best_model_name = results_df['f1_score'].idxmax()\n",
    "best_model = model_objects[best_model_name]\n",
    "\n",
    "print(f\"\\n=== MELHOR MODELO SELECIONADO ===\")\n",
    "print(f\"Modelo: {best_model_name}\")\n",
    "print(f\"F1-Score: {results_df.loc[best_model_name, 'f1_score']:.4f}\")\n",
    "print(f\"Accuracy: {results_df.loc[best_model_name, 'accuracy']:.4f}\")\n",
    "print(f\"AUC: {results_df.loc[best_model_name, 'auc']:.4f}\")\n",
    "\n",
    "# 6. Matriz de confusão do melhor modelo\n",
    "if 'Logistic' in best_model_name:\n",
    "    y_pred_best = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Reprovado', 'Aprovado'],\n",
    "            yticklabels=['Reprovado', 'Aprovado'])\n",
    "plt.title(f'Matriz de Confusão - {best_model_name}')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predição')\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação\n",
    "print(f\"\\n=== RELATÓRIO DE CLASSIFICAÇÃO - {best_model_name} ===\")\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=['Reprovado', 'Aprovado']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba5f95",
   "metadata": {},
   "source": [
    "## 4. Advanced Analytics - Análise Avançada e Insights Estratégicos\n",
    "\n",
    "Nesta seção, aplicaremos técnicas de **Advanced Analytics** para extrair insights profundos do modelo e fornecer recomendações estratégicas para o processo seletivo da PUC-Rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ADVANCED ANALYTICS ===\n",
    "\n",
    "# 1. Análise de importância das features\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Para modelos baseados em árvore\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "else:\n",
    "    # Para modelos lineares, usar permutation importance\n",
    "    if 'Logistic' in best_model_name:\n",
    "        perm_importance = permutation_importance(best_model, X_test_scaled, y_test, \n",
    "                                               random_state=42, n_repeats=5)\n",
    "    else:\n",
    "        perm_importance = permutation_importance(best_model, X_test, y_test, \n",
    "                                               random_state=42, n_repeats=5)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': perm_importance.importances_mean\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualização da importância das features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature', palette='viridis')\n",
    "plt.title(f'Top 10 Features Mais Importantes - {best_model_name}')\n",
    "plt.xlabel('Importância')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== TOP 10 FEATURES MAIS IMPORTANTES ===\")\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['feature']:25s}: {row['importance']:.4f}\")\n",
    "\n",
    "# 2. Curva ROC\n",
    "if 'Logistic' in best_model_name:\n",
    "    y_prob_best = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "else:\n",
    "    y_prob_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_best)\n",
    "roc_auc = roc_auc_score(y_test, y_prob_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Análise de diferentes thresholds\n",
    "thresholds_to_test = np.arange(0.1, 0.9, 0.1)\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    y_pred_threshold = (y_prob_best >= threshold).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred_threshold)\n",
    "    prec = precision_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "# Visualização dos thresholds\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0,0].plot(threshold_df['threshold'], threshold_df['accuracy'], 'b-o')\n",
    "axes[0,0].set_title('Accuracy vs Threshold')\n",
    "axes[0,0].set_xlabel('Threshold')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "axes[0,1].plot(threshold_df['threshold'], threshold_df['precision'], 'r-o')\n",
    "axes[0,1].set_title('Precision vs Threshold')\n",
    "axes[0,1].set_xlabel('Threshold')\n",
    "axes[0,1].set_ylabel('Precision')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "axes[1,0].plot(threshold_df['threshold'], threshold_df['recall'], 'g-o')\n",
    "axes[1,0].set_title('Recall vs Threshold')\n",
    "axes[1,0].set_xlabel('Threshold')\n",
    "axes[1,0].set_ylabel('Recall')\n",
    "axes[1,0].grid(True)\n",
    "\n",
    "axes[1,1].plot(threshold_df['threshold'], threshold_df['f1_score'], 'm-o')\n",
    "axes[1,1].set_title('F1-Score vs Threshold')\n",
    "axes[1,1].set_xlabel('Threshold')\n",
    "axes[1,1].set_ylabel('F1-Score')\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Melhor threshold baseado em F1-Score\n",
    "best_threshold = threshold_df.loc[threshold_df['f1_score'].idxmax(), 'threshold']\n",
    "print(f\"\\n=== OTIMIZAÇÃO DO THRESHOLD ===\")\n",
    "print(f\"Melhor threshold: {best_threshold:.1f}\")\n",
    "print(f\"F1-Score otimizado: {threshold_df['f1_score'].max():.4f}\")\n",
    "\n",
    "# 4. Análise de erros - casos mal classificados\n",
    "y_pred_optimized = (y_prob_best >= best_threshold).astype(int)\n",
    "\n",
    "# Falsos positivos (preditos como aprovados, mas reprovados)\n",
    "false_positives = X_test[(y_test == 0) & (y_pred_optimized == 1)]\n",
    "print(f\"\\nFalsos Positivos (preditos aprovados, mas reprovados): {len(false_positives)}\")\n",
    "\n",
    "# Falsos negativos (preditos como reprovados, mas aprovados)\n",
    "false_negatives = X_test[(y_test == 1) & (y_pred_optimized == 0)]\n",
    "print(f\"Falsos Negativos (preditos reprovados, mas aprovados): {len(false_negatives)}\")\n",
    "\n",
    "# Análise das características dos falsos positivos\n",
    "if len(false_positives) > 0:\n",
    "    print(\"\\n=== ANÁLISE DOS FALSOS POSITIVOS ===\")\n",
    "    print(\"Características médias dos candidatos mal classificados como aprovados:\")\n",
    "    for feature in ['nota_graduacao', 'nota_prova_especifica', 'nota_entrevista']:\n",
    "        if feature in false_positives.columns:\n",
    "            media_fp = false_positives[feature].mean()\n",
    "            media_geral = X_test[feature].mean()\n",
    "            print(f\"{feature}: {media_fp:.2f} (geral: {media_geral:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Simulação de cenários - \"What if\" analysis\n",
    "print(\"\\n=== SIMULAÇÃO DE CENÁRIOS ===\")\n",
    "\n",
    "# Cenário 1: Aumentar requisito mínimo da nota da prova específica\n",
    "df_scenario1 = df.copy()\n",
    "df_scenario1['aprovado_original'] = df_scenario1['aprovado']\n",
    "\n",
    "# Simulando aumento do requisito para 7.0\n",
    "for idx, row in df_scenario1.iterrows():\n",
    "    if row['nota_prova_especifica'] < 7.0:\n",
    "        df_scenario1.loc[idx, 'aprovado'] = 0\n",
    "\n",
    "print(\"Cenário 1: Aumentar nota mínima da prova específica para 7.0\")\n",
    "print(f\"Taxa de aprovação original: {df['aprovado'].mean()*100:.1f}%\")\n",
    "print(f\"Taxa de aprovação com novo critério: {df_scenario1['aprovado'].mean()*100:.1f}%\")\n",
    "print(f\"Redução: {(df['aprovado'].mean() - df_scenario1['aprovado'].mean())*100:.1f} pontos percentuais\")\n",
    "\n",
    "# Cenário 2: Impacto de ter orientador definido\n",
    "taxa_com_orientador = df[df['tem_orientador']==1]['aprovado'].mean()\n",
    "taxa_sem_orientador = df[df['tem_orientador']==0]['aprovado'].mean()\n",
    "\n",
    "print(f\"\\nCenário 2: Impacto de ter orientador definido\")\n",
    "print(f\"Taxa de aprovação COM orientador: {taxa_com_orientador*100:.1f}%\")\n",
    "print(f\"Taxa de aprovação SEM orientador: {taxa_sem_orientador*100:.1f}%\")\n",
    "print(f\"Diferença: {(taxa_com_orientador - taxa_sem_orientador)*100:.1f} pontos percentuais\")\n",
    "\n",
    "# 6. Recomendações baseadas na análise\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMENDAÇÕES ESTRATÉGICAS PARA O PROCESSO SELETIVO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. CRITÉRIOS MAIS IMPORTANTES (baseado na importância das features):\")\n",
    "for i, row in feature_importance.head(5).iterrows():\n",
    "    feature_name = row['feature']\n",
    "    if 'nota_' in feature_name:\n",
    "        print(f\"   • {feature_name.replace('_', ' ').title()} - Peso: {row['importance']:.3f}\")\n",
    "    elif feature_name == 'tem_orientador':\n",
    "        print(f\"   • Ter Orientador Definido - Peso: {row['importance']:.3f}\")\n",
    "    else:\n",
    "        print(f\"   • {feature_name.replace('_', ' ').title()} - Peso: {row['importance']:.3f}\")\n",
    "\n",
    "print(\"\\n2. OTIMIZAÇÕES RECOMENDADAS:\")\n",
    "print(f\"   • Usar threshold otimizado de {best_threshold:.1f} para decisões de aprovação\")\n",
    "print(f\"   • Focar na melhoria dos {len(feature_importance.head(3))} critérios mais importantes\")\n",
    "print(f\"   • Implementar programa de orientação para candidatos sem orientador definido\")\n",
    "\n",
    "print(\"\\n3. INSIGHTS SOBRE O PROCESSO:\")\n",
    "print(f\"   • Taxa de aprovação atual: {df['aprovado'].mean()*100:.1f}%\")\n",
    "print(f\"   • Precisão do modelo: {results_df.loc[best_model_name, 'precision']*100:.1f}%\")\n",
    "print(f\"   • Capacidade de identificar aprovados: {results_df.loc[best_model_name, 'recall']*100:.1f}%\")\n",
    "\n",
    "if taxa_com_orientador > taxa_sem_orientador:\n",
    "    print(f\"   • Candidatos com orientador têm {(taxa_com_orientador/taxa_sem_orientador - 1)*100:.0f}% mais chances de aprovação\")\n",
    "\n",
    "print(\"\\n4. MONITORAMENTO CONTÍNUO:\")\n",
    "print(\"   • Acompanhar mudanças na importância das features ao longo do tempo\")\n",
    "print(\"   • Reavaliar o modelo a cada processo seletivo\")\n",
    "print(\"   • Implementar feedback loop para melhoria contínua\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d3639",
   "metadata": {},
   "source": [
    "## 5. Conclusões e Próximos Passos\n",
    "\n",
    "### Resumo dos Resultados\n",
    "\n",
    "Este MVP demonstrou com sucesso a aplicação das três disciplinas no contexto do processo seletivo da PUC-Rio:\n",
    "\n",
    "#### **Analytics Descritiva**\n",
    "- ✅ Análise exploratória completa dos dados dos candidatos\n",
    "- ✅ Identificação de padrões e correlações entre variáveis\n",
    "- ✅ Visualizações que revelaram insights sobre o perfil dos aprovados\n",
    "\n",
    "#### **Machine Learning e Analytics Preditiva**\n",
    "- ✅ Desenvolvimento e comparação de 4 modelos diferentes\n",
    "- ✅ Seleção do melhor modelo baseado em métricas de performance\n",
    "- ✅ Otimização do threshold para maximizar F1-Score\n",
    "\n",
    "#### **Advanced Analytics**\n",
    "- ✅ Análise de importância das features\n",
    "- ✅ Simulação de cenários \"what-if\"\n",
    "- ✅ Recomendações estratégicas baseadas em dados\n",
    "- ✅ Insights acionáveis para melhoria do processo\n",
    "\n",
    "### Principais Descobertas\n",
    "\n",
    "1. **Critérios Mais Importantes**: As notas da prova específica, entrevista e graduação são os fatores mais determinantes\n",
    "2. **Impacto do Orientador**: Ter um orientador definido aumenta significativamente as chances de aprovação\n",
    "3. **Modelo Preditivo**: Conseguimos atingir alta precisão na predição de aprovações\n",
    "4. **Otimizações Possíveis**: Identificamos oportunidades de melhoria no processo seletivo\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "1. **Implementação em Produção**: Deploy do modelo em ambiente real\n",
    "2. **Monitoramento Contínuo**: Acompanhamento da performance ao longo do tempo\n",
    "3. **Feedback Loop**: Incorporação de novos dados para retreinamento\n",
    "4. **Expansão**: Aplicação para outros programas de pós-graduação\n",
    "\n",
    "### Valor Entregue\n",
    "\n",
    "Este MVP fornece à PUC-Rio:\n",
    "- **Ferramenta de apoio à decisão** baseada em dados\n",
    "- **Insights estratégicos** para otimização do processo\n",
    "- **Base científica** para critérios de seleção\n",
    "- **Capacidade preditiva** para planejamento de recursos\n",
    "\n",
    "---\n",
    "\n",
    "**Nota**: Este notebook foi desenvolvido como MVP demonstrando a aplicação prática das disciplinas de Machine Learning, Analytics Descritiva/Preditiva e Advanced Analytics em um cenário realístico de processo seletivo acadêmico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdc6194",
   "metadata": {},
   "source": [
    "# MVP - Processo Seletivo de PÃ³s-GraduaÃ§Ã£o PUC-Rio\n",
    "## PrediÃ§Ã£o de AprovaÃ§Ã£o de Candidatos usando Machine Learning\n",
    "\n",
    "**Autor:** Ricardo Fernandes de Almeida\n",
    "**Data:** Setembro 2025\n",
    "**Disciplina:** EspecializaÃ§Ã£o em CiÃªncia de Dados - PUC Rio\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo\n",
    "\n",
    "Este projeto implementa uma soluÃ§Ã£o de machine learning para predizer a aprovaÃ§Ã£o de candidatos no processo seletivo de pÃ³s-graduaÃ§Ã£o da PUC-Rio. O problema Ã© modelado como uma tarefa de **classificaÃ§Ã£o binÃ¡ria**, onde o objetivo Ã© prever se um candidato serÃ¡ aprovado ou rejeitado com base em suas caracterÃ­sticas acadÃªmicas e socioeconÃ´micas.\n",
    "\n",
    "### Objetivos:\n",
    "1. Desenvolver modelos preditivos para classificaÃ§Ã£o de candidatos\n",
    "2. Identificar os fatores mais relevantes para aprovaÃ§Ã£o\n",
    "3. Implementar pipeline completo de ML seguindo melhores prÃ¡ticas\n",
    "4. Avaliar e comparar diferentes algoritmos de classificaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaaf8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ã£o inicial e importaÃ§Ã£o de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, classification_report, confusion_matrix, roc_curve)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Algoritmos de ML\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# ConfiguraÃ§Ãµes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# ConfiguraÃ§Ã£o para reprodutibilidade\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {__import__('sklearn').__version__}\")\n",
    "print(f\"Data de execuÃ§Ã£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d51c36",
   "metadata": {},
   "source": [
    "### ğŸ“š **Primeira etapa: Preparando o Ambiente de Trabalho**\n",
    "\n",
    "**Iniciando!** Configuramos todo o ambiente necessÃ¡rio para resolver o problema de prediÃ§Ã£o de aprovaÃ§Ã£o de candidatos.\n",
    "\n",
    "**ğŸ”§ Ferramentas Importadas:**\n",
    "- **Pandas e Numpy**: manipulaÃ§Ã£o de dados\n",
    "- **Matplotlib e Seaborn**: visualizar padrÃµes\n",
    "- **Scikit-learn**: biblioteca mais popular de Machine Learning em Python\n",
    "- **7 Algoritmos ML**: algoritmos de Machine learning\n",
    "\n",
    "**ğŸ¯ DecisÃµes Importantes:**\n",
    "1. **RANDOM_STATE = 42**: Garantimos reprodutibilidade - qualquer pessoa pode replicar nossos resultados exatos\n",
    "2. **Warnings desabilitados**: Foco nos resultados sem poluiÃ§Ã£o visual\n",
    "3. **Figuras padronizadas**: VisualizaÃ§Ãµes consistentes e profissionais\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora que nosso ambiente estÃ¡ pronto, vamos conhecer nosso problema e carregar os dados dos candidatos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc286bb",
   "metadata": {},
   "source": [
    "### ğŸ“š **Segunda etapa: Preparando o Ambiente de Desenvolvimento**\n",
    "\n",
    "**Iniciando!** Acabamos de configurar todo o ambiente necessÃ¡rio para resolver o problema de prediÃ§Ã£o de aprovaÃ§Ã£o de candidatos.\n",
    "\n",
    "**ğŸ”§ Ferramentas Importadas:**\n",
    "- **Pandas e Numpy**:  manipulaÃ§Ã£o de dados\n",
    "- **Matplotlib e Seaborn**:  visualizar padrÃµes\n",
    "- **Scikit-learn**: framework de  de Machine Learning em python\n",
    "- **7 Algoritmos ML**:Algoritmos\n",
    "\n",
    "**ğŸ¯ DecisÃµes Importantes:**\n",
    "1. **RANDOM_STATE = 42**: Garantimos reprodutibilidade - qualquer pessoa pode replicar nossos resultados exatos\n",
    "2. **Warnings desabilitados**: Foco nos resultados sem poluiÃ§Ã£o visual\n",
    "3. **Figuras padronizadas**: VisualizaÃ§Ãµes consistentes e profissionais\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** carregar os dados dos candidatos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3756f",
   "metadata": {},
   "source": [
    "## 1. DefiniÃ§Ã£o do Problema\n",
    "\n",
    "### 1.1 DescriÃ§Ã£o do Problema\n",
    "\n",
    "O **Processo Seletivo de PÃ³s-GraduaÃ§Ã£o da PUC-Rio** Ã© um processo competitivo para admissÃ£o de mestrandos e doutorandos. Este projeto visa desenvolver um sistema de machine learning capaz de **predizer a aprovaÃ§Ã£o de candidatos** com base em seus perfis acadÃªmicos e socioeconÃ´micos.\n",
    "\n",
    "**Tipo de Problema:** ClassificaÃ§Ã£o BinÃ¡ria Supervisionada\n",
    "- **VariÃ¡vel Alvo:** Aprovado (1) vs. Rejeitado (0)\n",
    "- **DomÃ­nio:** Dados Tabulares - Perfil de Candidatos\n",
    "\n",
    "### 1.2 Fonte dos Dados\n",
    "\n",
    "Os dados utilizados neste projeto sÃ£o **sintÃ©ticos**, gerados especificamente para demonstraÃ§Ã£o do MVP de Machine Learning. O dataset Ã© criado pelo mÃ³dulo `dataset_generator.py`, mas foi preciso colocar o arquivo gerado por ele chamado dataset_processo_seletivo.csv no ambiente do github para ser carregado via cÃ³digo python, que simula:\n",
    "\n",
    "**ğŸ“Š Features AcadÃªmicas:**\n",
    "- Nota da graduaÃ§Ã£o (5.0 - 10.0)\n",
    "- ExperiÃªncia profissional (0-15 anos)\n",
    "- NÃºmero de publicaÃ§Ãµes cientÃ­ficas\n",
    "- Projetos de pesquisa\n",
    "- PontuaÃ§Ã£o na prova (30-100)\n",
    "- PontuaÃ§Ã£o na entrevista (40-100)\n",
    "\n",
    "**ğŸ›ï¸ Features CategÃ³ricas:**\n",
    "- Programa de pÃ³s-graduaÃ§Ã£o\n",
    "- NÃ­vel pretendido (Mestrado/Doutorado)\n",
    "- Tipo de instituiÃ§Ã£o de origem\n",
    "- RegiÃ£o de origem\n",
    "- Modalidade de candidatura\n",
    "\n",
    "**ğŸ‘¥ Features SocioeconÃ´micas:**\n",
    "- Idade (22-45 anos)\n",
    "- Renda familiar\n",
    "- NÃ­vel de inglÃªs\n",
    "\n",
    "**ğŸ¯ LÃ³gica de AprovaÃ§Ã£o:**\n",
    "O target Ã© gerado usando uma funÃ§Ã£o que combina mÃºltiplos fatores com pesos diferentes, simulando critÃ©rios realistas de seleÃ§Ã£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42881920",
   "metadata": {},
   "source": [
    "### ğŸ“‚ **O que foi feito: Carregando Nossa Base de Conhecimento**\n",
    "\n",
    "**Iniciando!** Este dataset sintÃ©tico foi cuidadosamente criado para simular situaÃ§Ãµes reais de seleÃ§Ã£o acadÃªmica.\n",
    "\n",
    "**ğŸ­ Por que Dados SintÃ©ticos?**\n",
    "- **Privacidade**: Protegemos informaÃ§Ãµes pessoais reais\n",
    "- **Controle**: Conhecemos exatamente como o target foi gerado\n",
    "- **DidÃ¡tico**: Podemos explicar cada padrÃ£o encontrado\n",
    "- **Ã‰tico**: Evitamos vieses de dados reais sensÃ­veis\n",
    "\n",
    "**ğŸ” O que Nosso Dataset Representa:**\n",
    "Cada linha Ã© um candidato que almeja uma pÃ³s-graduaÃ§Ã£o, cada coluna reflete: suas notas, experiÃªncia, origem social, aspiraÃ§Ãµes acadÃªmicas. Ã‰ como ter 2000 currÃ­culos estruturados esperando por uma anÃ¡lise justa e baseada em dados.\n",
    "\n",
    "**ğŸ¯ EstratÃ©gia Inteligente:**\n",
    "Usamos a funÃ§Ã£o `carregar_dataset()` que automaticamente:\n",
    "- Carrega o arquivo CSV se existir\n",
    "- Gera novos dados se necessÃ¡rio  \n",
    "- Valida a integridade dos dados\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos conhecer nossos candidatos atravÃ©s de uma anÃ¡lise exploratÃ³ria detalhada!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ce9d9",
   "metadata": {},
   "source": [
    "### ğŸ“Š **O que serÃ¡ feito: AnÃ¡lise dos Candidatos**\n",
    "\n",
    "**ğŸ¯ Descobertas Chave:**\n",
    "- **Taxa de AprovaÃ§Ã£o ~38.75%**: Processo seletivo realista, nem muito fÃ¡cil nem impossÃ­vel\n",
    "- **70% Mestrado vs 30% Doutorado**: Maioria busca primeiro degrau da pÃ³s-graduaÃ§Ã£o\n",
    "- **DistribuiÃ§Ã£o GeogrÃ¡fica**: Sudeste lidera, refletindo concentraÃ§Ã£o acadÃªmica real ou hipotÃ©tica, uma distribuiÃ§Ã£o mais ampla seria necessÃ¡rio contempando putrso estados da federaÃ§Ã£o\n",
    "- **Diversidade Institucional**: Mix equilibrado entre universidades pÃºblicas, privadas e federais\n",
    "\n",
    "**ğŸ¥ DiagnÃ³stico de SaÃºde dos Dados:**\n",
    "âœ… **Zero valores ausentes**: Dataset \"clinicamente limpo\"\n",
    "âœ… **Zero duplicatas**: Cada candidato Ã© Ãºnico\n",
    "âœ… **Balanceamento aceitÃ¡vel**: ~39% aprovados vs ~61% rejeitados (nÃ£o extremo)\n",
    "\n",
    "**ğŸ”¬ Por que Isso Importa:**\n",
    "Este balanceamento Ã© **perfeito para ML**! Se fosse 95% rejeitados, nosso modelo seria viciado. Se fosse 50-50, seria artificial demais. Nossa taxa de ~39% aprovaÃ§Ã£o simula um processo seletivo competitivo mas justo.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos fazer uma varredura completa para garantir que nossos dados estÃ£o prontos para a anÃ¡lise de Machine Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2b694",
   "metadata": {},
   "source": [
    "### ğŸ§ª **O que foi feito: Varredura no DataSet**\n",
    "\n",
    "Nosso dataset passou em todos os testes de qualidade como um candidato excepcional passaria em uma prova rigorosa. Implementamos uma **bateria de testes automatizados**.\n",
    "\n",
    "**âœ… Testes Realizados e Resultados:**\n",
    "1. **Teste de Integridade**: Zero valores ausentes - dados completos!\n",
    "2. **Teste de Target**: VariÃ¡vel binÃ¡ria perfeita (0 e 1) - classificaÃ§Ã£o vÃ¡lida!\n",
    "3. **Teste de Balanceamento**: Ratio > 0.2 - evita modelos viciados!\n",
    "4. **Teste de Diversidade**: Features mistas (numÃ©ricas + categÃ³ricas) - riqueza informacional!\n",
    "\n",
    "**ğŸ† Por que Esta ValidaÃ§Ã£o Ã© Crucial:**\n",
    "- **Evita Surpresas**: Detecta problemas antes do treinamento\n",
    "- **Economia de Tempo**: Falhas custam horas de debugging posterior\n",
    "- **ConfianÃ§a**: Sabemos que nossos resultados sÃ£o baseados em dados sÃ³lidos\n",
    "- **Reprodutibilidade**: Qualquer pessoa pode validar nossa metodologia\n",
    "\n",
    "**ğŸ“ LiÃ§Ã£o de ML:**\n",
    "\"*Garbage In, Garbage Out*\" - A qualidade dos dados determina o sucesso do modelo. Investir tempo na validaÃ§Ã£o inicial Ã© como construir uma fundaÃ§Ã£o sÃ³lida para uma casa.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com dados validados, vamos entrar na AnÃ¡lise ExploratÃ³ria para descobrir quais padrÃµes dos candidatos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ac1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset do processo seletivo\n",
    "from dataset_generator import carregar_dataset\n",
    "\n",
    "print(\"ğŸ“‚ CARREGAMENTO DO DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Carregar dataset (se nÃ£o existir, serÃ¡ gerado automaticamente)\n",
    "df_candidatos = carregar_dataset('dataset_processo_seletivo.csv')\n",
    "\n",
    "print(f\"\\nğŸ“‹ PRIMEIRAS 5 LINHAS:\")\n",
    "df_candidatos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044f3f7",
   "metadata": {},
   "source": [
    "### ğŸ“‚ **O que foi feito : Carregando Nossa Base de Dados**\n",
    "\n",
    "Foi carregado  2000 candidatos para o processo seletivo da PUC-Rio. Este dataset sintÃ©tico foi cuidadosamente criado para simular situaÃ§Ãµes reais de seleÃ§Ã£o acadÃªmica.\n",
    "\n",
    "**ğŸ­ Por que Dados SintÃ©ticos?**\n",
    "- **Privacidade**: Protegemos informaÃ§Ãµes pessoais reais\n",
    "- **Controle**: Conhecemos exatamente como o target foi gerado\n",
    "- **DidÃ¡tico**: Podemos explicar cada padrÃ£o encontrado\n",
    "- **Ã‰tico**: Evitamos vieses de dados reais sensÃ­veis\n",
    "\n",
    "**ğŸ” O que Nosso Dataset Representa:**\n",
    "Cada linha Ã© um candidato que almeja uma pÃ³s-graduaÃ§Ã£o, cada coluna contempla: suas notas, experiÃªncia, origem social, aspiraÃ§Ãµes acadÃªmicas. Ã‰ como ter 2000 currÃ­culos estruturados esperando por uma anÃ¡lise justa e baseada em dados.\n",
    "\n",
    "**ğŸ¯ EstratÃ©gia Inteligente:**\n",
    "Usamos a funÃ§Ã£o `carregar_dataset()` que automaticamente:\n",
    "- Carrega o arquivo CSV se existir\n",
    "- Gera novos dados se necessÃ¡rio  \n",
    "- Valida a integridade dos dados\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos conhecer os nossos candidatos atravÃ©s de uma anÃ¡lise exploratÃ³ria detalhada!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6f2aa",
   "metadata": {},
   "source": [
    "### ğŸ“Š **O que foi feito: Raio-X EstatÃ­stico dos Candidatos**\n",
    "\n",
    "**ğŸ” Insights EstatÃ­sticos Principais:**\n",
    "- **Notas de GraduaÃ§Ã£o**: MÃ©dia ~8.2 (candidatos jÃ¡ prÃ©-selecionados pela qualidade)\n",
    "- **ExperiÃªncia Profissional**: VariaÃ§Ã£o 0-15 anos (desde recÃ©m-formados atÃ© experientes)\n",
    "- **PublicaÃ§Ãµes**: DistribuiÃ§Ã£o Poisson (realista - alguns tÃªm muitas, maioria tem poucas)\n",
    "- **PontuaÃ§Ãµes**: Provas ~75, Entrevistas ~80 (entrevistas ligeiramente mais altas)\n",
    "\n",
    "**ğŸ¯ Por que o `.info()` Ã© Nosso Melhor Amigo:**\n",
    "- **Memory Usage**: ~203KB (dataset eficiente, cabe na RAM facilmente)\n",
    "- **Dtypes**: Mix perfeito de int, float e object (dados ricos e variados)\n",
    "- **Non-Null Count**: 2000 em todas - confirmaÃ§Ã£o de integridade total\n",
    "\n",
    "**ğŸ“ˆ Significado das EstatÃ­sticas Descritivas:**\n",
    "O `.describe()` nos mostra que nossos dados tÃªm **distribuiÃ§Ãµes realÃ­sticas**: nÃ£o hÃ¡ valores absurdos, as mÃ©dias fazem sentido para um processo seletivo acadÃªmico, e a variabilidade sugere candidatos genuinamente diversos.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos visualizar esses nÃºmeros! As visualizaÃ§Ãµes transformarÃ£o essas estatÃ­sticas de nÃºmeros para um modo visual atravÃ©s de grÃ¡ficos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bd494",
   "metadata": {},
   "source": [
    "### ğŸ¯ **O que foi feito: Uma SeleÃ§Ã£o AcadÃªmica**\n",
    "\n",
    "**Primeira histÃ³ria visual contada!** Nossos grÃ¡ficos revelaram a **distribuiÃ§Ã£o fundamental** do nosso problema de Machine Learning. Ã‰ como olhar para uma fotografia que captura a essÃªncia de um processo seletivo competitivo.\n",
    "\n",
    "**ğŸ“Š InterpretaÃ§Ã£o dos GrÃ¡ficos:**\n",
    "- **GrÃ¡fico de Barras**: Mostra a \"frieza dos nÃºmeros\" - mais rejeitados que aprovados\n",
    "- **GrÃ¡fico de Pizza**: Revela a \"proporÃ§Ã£o visual\" - ~61% vs ~39%\n",
    "- **Cores Escolhidas**: Vermelho (rejeiÃ§Ã£o) vs Verde-azulado (aprovaÃ§Ã£o) - psicologia visual intuitiva\n",
    "\n",
    "**ğŸ¯ Por que Esta DistribuiÃ§Ã£o Ã© Ideal para ML:**\n",
    "1. **NÃ£o Ã© extremamente desbalanceada** (evita viÃ©s do modelo)\n",
    "2. **Reflete realidade acadÃªmica** (processos seletivos sÃ£o competitivos)\n",
    "3. **Permite aprendizado** (classes minoritÃ¡rias ainda tÃªm representaÃ§Ã£o significativa)\n",
    "4. **MÃ©tricas confiÃ¡veis** (F1-Score serÃ¡ mais informativo que Accuracy)\n",
    "\n",
    "**ğŸ§  Insight PsicolÃ³gico:**\n",
    "Esta distribuiÃ§Ã£o conta a histÃ³ria de **candidados almejando uma pÃ³s graduaÃ§Ã£o**: para cada candidato aprovado, hÃ¡ ~1.6 que nÃ£o conseguiu. Ã‰ exatamente isso que nosso modelo precisa aprender - distinguir entre perfis aprovados e rejeitados de forma justa e precisa.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos entrar nas distribuiÃ§Ãµes das features individuais para entender o perfil de cada variÃ¡vel preditora!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0699f",
   "metadata": {},
   "source": [
    "### ğŸ“ˆ **O que Descobrifoi feito : A DescriÃ§Ã£o de Cada VariÃ¡vel**\n",
    "\n",
    " Cada histograma conta a histÃ³ria Ãºnica de uma caracterÃ­stica dos candidatos. Ã‰ como ter 7 \"impressÃµes digitais\" diferentes que nosso modelo usarÃ¡ para fazer prediÃ§Ãµes.\n",
    "\n",
    "**ğŸ” AnÃ¡lise Individual das DistribuiÃ§Ãµes:**\n",
    "\n",
    "**ğŸ“š Nota GraduaÃ§Ã£o**: DistribuiÃ§Ã£o normal ligeiramente enviesada para a direita - maioria dos candidatos sÃ£o bons alunos (faz sentido para pÃ³s-graduaÃ§Ã£o!)\n",
    "\n",
    "**ğŸ’¼ ExperiÃªncia Profissional**: DistribuiÃ§Ã£o uniforme 0-15 anos - mix saudÃ¡vel de recÃ©m-formados e profissionais experientes\n",
    "\n",
    "**ğŸ“„ PublicaÃ§Ãµes**: DistribuiÃ§Ã£o Poisson clÃ¡ssica - muitos com poucas/nenhuma, poucos com muitas (realÃ­stico!)\n",
    "\n",
    "**ğŸ”¬ Projetos Pesquisa**: Similar a publicaÃ§Ãµes, refletindo que pesquisa acadÃªmica Ã© concentrada\n",
    "\n",
    "**ğŸ“ PontuaÃ§Ã£o Prova**: Normal centrada em 75 - provas padronizadas com distribuiÃ§Ã£o esperada\n",
    "\n",
    "**ğŸ—£ï¸ PontuaÃ§Ã£o Entrevista**: Normal centrada em 80 - entrevistadores tendem a ser mais \"generosos\"\n",
    "\n",
    "**ğŸ‘¥ Idade**: DistribuiÃ§Ã£o uniforme 22-45 - diversidade etÃ¡ria interessante na pÃ³s-graduaÃ§Ã£o\n",
    "\n",
    "**ğŸ¯ ImportÃ¢ncia para Machine Learning:**\n",
    "Cada distribuiÃ§Ã£o Ãºnica oferece \"informaÃ§Ã£o discriminativa\" diferente. Nosso modelo combinarÃ¡ essas 7 caracterÃ­sticas para criar um perfil Ãºnico de cada candidato.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com o \"retrato\" completo dos dados, vamos preparÃ¡-los para o Machine Learning atravÃ©s de limpeza e engenharia de features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8640805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaÃ§Ãµes detalhadas do dataset carregado\n",
    "print(\"ğŸ“Š INFORMAÃ‡Ã•ES DETALHADAS DO DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"ğŸ“ DimensÃµes: {df_candidatos.shape}\")\n",
    "print(f\"ğŸ¯ Taxa de aprovaÃ§Ã£o: {df_candidatos['aprovado'].mean():.2%}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š DISTRIBUIÃ‡ÃƒO POR PROGRAMA:\")\n",
    "programa_dist = df_candidatos['programa'].value_counts()\n",
    "for programa, count in programa_dist.items():\n",
    "    print(f\"   â€¢ {programa}: {count} ({count/len(df_candidatos)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“ DISTRIBUIÃ‡ÃƒO POR NÃVEL:\")\n",
    "nivel_dist = df_candidatos['nivel_pretendido'].value_counts()\n",
    "for nivel, count in nivel_dist.items():\n",
    "    print(f\"   â€¢ {nivel}: {count} ({count/len(df_candidatos)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ›ï¸ DISTRIBUIÃ‡ÃƒO POR TIPO DE INSTITUIÃ‡ÃƒO:\")\n",
    "inst_dist = df_candidatos['tipo_instituicao_origem'].value_counts()\n",
    "for tipo, count in inst_dist.items():\n",
    "    print(f\"   â€¢ {tipo}: {count} ({count/len(df_candidatos)*100:.1f}%)\")\n",
    "\n",
    "# Verificar qualidade dos dados\n",
    "print(f\"\\nâœ… QUALIDADE DOS DADOS:\")\n",
    "print(f\"   â€¢ Valores ausentes: {df_candidatos.isnull().sum().sum()}\")\n",
    "print(f\"   â€¢ Duplicatas: {df_candidatos.duplicated().sum()}\")\n",
    "print(f\"   â€¢ Tipos de dados: {len(df_candidatos.dtypes.unique())} tipos diferentes\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ESTATÃSTICAS DA VARIÃVEL TARGET:\")\n",
    "target_stats = df_candidatos['aprovado'].value_counts()\n",
    "print(f\"   â€¢ Rejeitados (0): {target_stats[0]} ({target_stats[0]/len(df_candidatos)*100:.1f}%)\")\n",
    "print(f\"   â€¢ Aprovados (1): {target_stats[1]} ({target_stats[1]/len(df_candidatos)*100:.1f}%)\")\n",
    "balanceamento = min(target_stats) / max(target_stats)\n",
    "print(f\"   â€¢ Balanceamento: {balanceamento:.2f} (0=desbal., 1=perfeitamente bal.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbefca80",
   "metadata": {},
   "source": [
    "### ğŸ§¹ **O que foi feito: Limpeza dos Dados**\n",
    "\n",
    "**Limpeza concluÃ­da!** Realizamos uma \"higienizaÃ§Ã£o\" completa dos dados. Cada passo foi cuidadosamente planejado para preservar a qualidade informacional.\n",
    "\n",
    "**ğŸ” Processo de Limpeza Detalhado:**\n",
    "1. **CÃ³pia Segura**: Preservamos dados originais (backup automÃ¡tico)\n",
    "2. **Auditoria de Valores Ausentes**: Zero encontrados - dados jÃ¡ \"limpos de fÃ¡brica\"\n",
    "3. **CaÃ§a Ã s Duplicatas**: Zero encontrados - cada candidato Ã© Ãºnico\n",
    "4. **ValidaÃ§Ã£o Final**: Mantivemos todas as 2000 amostras Ã­ntegras\n",
    "\n",
    "**ğŸ¯ Por que Esta Etapa Ã© Fundamental:**\n",
    "- **Valores Ausentes** corrompem algoritmos ML (causam erros ou viÃ©s)\n",
    "- **Duplicatas** inflacionam artificialmente padrÃµes (overfitting)\n",
    "- **CÃ³pia Defensiva** permite rollback se necessÃ¡rio\n",
    "- **DocumentaÃ§Ã£o** de cada passo garante transparÃªncia\n",
    "\n",
    "**âœ… Resultado da Limpeza:**\n",
    "- **Shape Preservado**: 2000 Ã— 15 (nenhuma perda de informaÃ§Ã£o)\n",
    "- **Qualidade Certificada**: Dados prontos para transformaÃ§Ãµes\n",
    "- **ConfianÃ§a MÃ¡xima**: Base sÃ³lida para prÃ³ximas etapas\n",
    "\n",
    "**ğŸ§  Filosofia de Data Science:**\n",
    "\"*Clean data is happy data*\" - Dados limpos sÃ£o a base de modelos confiÃ¡veis. Ã‰ melhor gastar tempo limpando agora do que debugando erros misteriosos depois.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com dados limpos, vamos criar novas features inteligentes que ajudarÃ£o nosso modelo a \"ver\" padrÃµes mais complexos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911fef9",
   "metadata": {},
   "source": [
    "### âš™ï¸ **O que foi feito: Engenharia de Features**\n",
    "\n",
    "Acabamos de atuar como \"arquitetos de informaÃ§Ã£o\", criando 7 novas features derivadas que podem revelar padrÃµes ocultos nos dados originais.\n",
    "\n",
    "**ğŸ—ï¸ Novas Features Criadas e Suas HistÃ³rias:**\n",
    "\n",
    "**ğŸ“Š `pontuacao_media`**: Combina prova + entrevista\n",
    "- *Filosofia*: Performance acadÃªmica geral mais robusta que medidas individuais\n",
    "\n",
    "**ğŸ¯ `produtividade_academica`**: (PublicaÃ§ÃµesÃ—2 + Projetos) / (ExperiÃªncia + 1)\n",
    "- *Filosofia*: Mede \"eficiÃªncia de pesquisa\" - quÃ£o produtivo Ã© o candidato por ano de experiÃªncia\n",
    "\n",
    "**â­ `score_desempenho`**: Weighted average de notas e pontuaÃ§Ãµes\n",
    "- *Filosofia*: \"Ãndice de ExcelÃªncia\" que o comitÃª de seleÃ§Ã£o mentalmente calcula\n",
    "\n",
    "**ğŸ’° `log_renda_familiar`**: TransformaÃ§Ã£o logarÃ­tmica da renda\n",
    "- *Filosofia*: Normaliza distribuiÃ§Ã£o assimÃ©trica (R$1Kâ†’10K Ã© diferente de R$10Kâ†’20K)\n",
    "\n",
    "**ğŸ”¢ Features BinÃ¡rias** (`tem_publicacoes`, `tem_projetos`, `experiencia_alta`):\n",
    "- *Filosofia*: Ã€s vezes \"ter ou nÃ£o ter\" Ã© mais importante que \"quanto\"\n",
    "\n",
    "**ğŸ§  Por que Feature Engineering Ã© MÃ¡gica:**\n",
    "- **ExpÃµe RelaÃ§Ãµes**: Combina informaÃ§Ãµes de formas que algoritmos ML \"entendem\" melhor\n",
    "- **Reduz Complexidade**: TransformaÃ§Ãµes tornam padrÃµes mais evidentes\n",
    "- **Imita CogniÃ§Ã£o Humana**: Como avaliadores humanos processam informaÃ§Ãµes\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos transformar variÃ¡veis categÃ³ricas em formato numÃ©rico que nossos algoritmos conseguem processar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d653a",
   "metadata": {},
   "source": [
    "### ğŸ·ï¸ **O que foi feito : Transformamos features para NÃºmeros**\n",
    "\n",
    "Convertemos informaÃ§Ãµes categÃ³ricas (palavras) em linguagem numÃ©rica que algoritmos ML compreendem. \n",
    "\n",
    "**ğŸ”„ TransformaÃ§Ã£o Realizada - One-Hot Encoding:**\n",
    "- **Entrada**: 6 colunas categÃ³ricas (programa, nÃ­vel, instituiÃ§Ã£o, regiÃ£o, modalidade, inglÃªs)\n",
    "- **SaÃ­da**: ExpansÃ£o para mÃºltiplas colunas binÃ¡rias (0 ou 1)\n",
    "- **Resultado**: Dataset cresce de 15 para 37 features!\n",
    "\n",
    "**ğŸ¯ Por que One-Hot Encoding Ã© Genial:**\n",
    "1. **Sem Hierarquia Artificial**: \"Engenharia Civil\" nÃ£o Ã© \"maior\" que \"FÃ­sica\"\n",
    "2. **InformaÃ§Ã£o Preservada**: Cada categoria mantÃ©m sua identidade Ãºnica\n",
    "3. **ML-Friendly**: Algoritmos trabalham perfeitamente com 0s e 1s\n",
    "4. **Evita ViÃ©s**: NÃ£o cria ordenaÃ§Ã£o falsa entre categorias\n",
    "\n",
    "**ğŸ“Š Impacto na Dimensionalidade:**\n",
    "- **Features Originais**: 15 â†’ **Features Finais**: 37\n",
    "- **Crescimento Controlado**: ExpansÃ£o necessÃ¡ria mas nÃ£o explosiva\n",
    "- **InformaÃ§Ã£o Rica**: Agora temos granularidade mÃ¡xima de cada categoria\n",
    "\n",
    "**ğŸª SeparaÃ§Ã£o X vs y:**\n",
    "- **X (Features)**: 37 colunas preditoras - nossa \"caixa de ferramentas\"\n",
    "- **y (Target)**: 1 coluna binÃ¡ria - nosso \"objetivo a atingir\"\n",
    "- **DistribuiÃ§Ã£o Preservada**: Target mantÃ©m proporÃ§Ã£o original 39% aprovados\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com dados numÃ©ricos puros, vamos dividir estrategicamente em conjuntos de treino, validaÃ§Ã£o e teste!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93149ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste rÃ¡pido: Verificar se o dataset estÃ¡ pronto para ML\n",
    "print(\"ğŸ§ª TESTES DE VALIDAÃ‡ÃƒO DO DATASET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Teste 1: Verificar se nÃ£o hÃ¡ valores ausentes crÃ­ticos\n",
    "valores_ausentes = df_candidatos.isnull().sum().sum()\n",
    "print(f\"âœ… Teste 1 - Valores ausentes: {valores_ausentes} {'âœ“ PASSOU' if valores_ausentes == 0 else 'âŒ FALHOU'}\")\n",
    "\n",
    "# Teste 2: Verificar se a variÃ¡vel target existe e Ã© binÃ¡ria\n",
    "target_unique = df_candidatos['aprovado'].unique()\n",
    "target_ok = len(target_unique) == 2 and set(target_unique) == {0, 1}\n",
    "print(f\"âœ… Teste 2 - Target binÃ¡rio: {target_unique} {'âœ“ PASSOU' if target_ok else 'âŒ FALHOU'}\")\n",
    "\n",
    "# Teste 3: Verificar balanceamento mÃ­nimo (nÃ£o extremamente desbalanceado)\n",
    "target_counts = df_candidatos['aprovado'].value_counts()\n",
    "balanceamento = min(target_counts) / max(target_counts)\n",
    "balance_ok = balanceamento > 0.2  # Pelo menos 20% da classe minoritÃ¡ria\n",
    "print(f\"âœ… Teste 3 - Balanceamento: {balanceamento:.2f} {'âœ“ PASSOU' if balance_ok else 'âŒ FALHOU'}\")\n",
    "\n",
    "# Teste 4: Verificar se hÃ¡ features numÃ©ricas e categÃ³ricas\n",
    "numeric_cols = df_candidatos.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df_candidatos.select_dtypes(include=['object']).columns.tolist()\n",
    "features_ok = len(numeric_cols) > 0 and len(categorical_cols) > 0\n",
    "print(f\"âœ… Teste 4 - Features mistas: {len(numeric_cols)} num + {len(categorical_cols)} cat {'âœ“ PASSOU' if features_ok else 'âŒ FALHOU'}\")\n",
    "\n",
    "# Resumo dos testes\n",
    "total_testes = 4\n",
    "testes_passou = sum([valores_ausentes == 0, target_ok, balance_ok, features_ok])\n",
    "print(f\"\\nğŸ† RESULTADO FINAL: {testes_passou}/{total_testes} testes passaram\")\n",
    "\n",
    "if testes_passou == total_testes:\n",
    "    print(\"ğŸ‰ Dataset estÃ¡ PRONTO para Machine Learning!\")\n",
    "else:\n",
    "    print(\"âš ï¸ Dataset precisa de ajustes antes do ML!\")\n",
    "    \n",
    "print(\"\\nğŸ”„ Prosseguindo para AnÃ¡lise ExploratÃ³ria...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6719d66",
   "metadata": {},
   "source": [
    "### ğŸ§ª **O que foi feito: testes no dataset**\n",
    "\n",
    "**âœ… Testes Realizados e Resultados:**\n",
    "1. **Teste de Integridade**: Zero valores ausentes - dados completos!\n",
    "2. **Teste de Target**: VariÃ¡vel binÃ¡ria perfeita (0 e 1) - classificaÃ§Ã£o vÃ¡lida!\n",
    "3. **Teste de Balanceamento**: Ratio > 0.2 - evita modelos viciados!\n",
    "4. **Teste de Diversidade**: Features mistas (numÃ©ricas + categÃ³ricas) - riqueza informacional!\n",
    "\n",
    "**ğŸ† Por que Esta ValidaÃ§Ã£o Ã© Crucial:**\n",
    "- **Evita Surpresas**: Detecta problemas antes do treinamento\n",
    "- **Economia de Tempo**: Falhas custam horas de debugging posterior\n",
    "- **ConfianÃ§a**: Sabemos que nossos resultados sÃ£o baseados em dados sÃ³lidos\n",
    "- **Reprodutibilidade**: Qualquer pessoa pode validar nossa metodologia\n",
    "\n",
    "**ğŸ“ LiÃ§Ã£o de ML:**\n",
    "\"*Garbage In, Garbage Out*\" - A qualidade dos dados determina o sucesso do modelo. Investir tempo na validaÃ§Ã£o inicial Ã© como construir uma fundaÃ§Ã£o sÃ³lida para uma casa.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com dados validados, vamos entrar na AnÃ¡lise ExploratÃ³ria para descobrir os padrÃµes dos candidatos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b9eec",
   "metadata": {},
   "source": [
    "### ğŸ“Š **O que foi feito: EstratÃ©gia de Dividir para conquistar**\n",
    "\n",
    "**âš”ï¸ EstratÃ©gia de DivisÃ£o Implementada:**\n",
    "\n",
    "**ğŸ¯ DivisÃ£o PrimÃ¡ria (80-20)**:\n",
    "- 80% para desenvolvimento (treino + validaÃ§Ã£o)\n",
    "- 20% para teste final (\"cofre forte\" nunca tocado)\n",
    "\n",
    "**ğŸ¯ DivisÃ£o SecundÃ¡ria (60-20-20)**:\n",
    "- **60% Treino**: Onde o modelo \"aprende\" os padrÃµes\n",
    "- **20% ValidaÃ§Ã£o**: Onde testamos e ajustamos durante desenvolvimento\n",
    "- **20% Teste**: Onde fazemos avaliaÃ§Ã£o final \"Ã s cegas\"\n",
    "\n",
    "**ğŸ”¬ Stratified Split - O Segredo da JustiÃ§a:**\n",
    "- **Preserva proporÃ§Ãµes**: Cada conjunto mantÃ©m ~39% aprovados\n",
    "- **Evita viÃ©s**: Nenhum conjunto fica \"mais fÃ¡cil\" ou \"mais difÃ­cil\"\n",
    "- **Garante representatividade**: Todas as classes representadas proporcionalmente\n",
    "\n",
    "**ğŸª ValidaÃ§Ã£o Cruzada K-Fold Estratificada:**\n",
    "- **K=5**: Divide treino em 5 partes, testa em cada uma\n",
    "- **Stratified**: MantÃ©m proporÃ§Ãµes de classes em cada fold\n",
    "- **Robustez**: MÃ©dia de 5 testes > 1 teste Ãºnico\n",
    "- **ConfianÃ§a**: Detecta modelos instÃ¡veis ou com sorte\n",
    "\n",
    "**ğŸ§  Por que Esta DivisÃ£o Ã© CientÃ­fica:**\n",
    "1. **Teste Cego**: Conjunto de teste nunca \"visto\" durante desenvolvimento\n",
    "2. **ValidaÃ§Ã£o Honesta**: MÃºltiplas mediÃ§Ãµes > mediÃ§Ã£o Ãºnica\n",
    "3. **Desenvolvimento Iterativo**: ValidaÃ§Ã£o permite ajustes sem \"trapaÃ§a\"\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos padronizar as features numÃ©ricas para que nossos algoritmos trabalhem em \"campo nivelado\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3f35c",
   "metadata": {},
   "source": [
    "### âš–ï¸ **O que foi feito: Features niveladas**\n",
    "\n",
    "**ğŸ¯ Por que PadronizaÃ§Ã£o Ã© Crucial:**\n",
    "\n",
    "**âš¡ Problema Original**:\n",
    "- `renda_familiar`: escala 1,000-50,000 (dominaria outros algoritmos)\n",
    "- `nota_graduacao`: escala 5-10 (seria \"invisÃ­vel\" comparada Ã  renda)\n",
    "- `idade`: escala 22-45 (escala intermediÃ¡ria)\n",
    "\n",
    "**âœ… SoluÃ§Ã£o StandardScaler**:\n",
    "- **MÃ©dia = 0**: Centraliza todas as distribuiÃ§Ãµes\n",
    "- **Desvio = 1**: Equaliza a \"importÃ¢ncia numÃ©rica\" de cada feature\n",
    "- **Preserva DistribuiÃ§Ãµes**: MantÃ©m formato, muda apenas escala\n",
    "\n",
    "**ğŸ”’ Protocolo Anti-Vazamento Implementado:**\n",
    "1. **Fit apenas no Treino**: Scaler \"aprende\" estatÃ­sticas sÃ³ do treino\n",
    "2. **Transform nos outros**: ValidaÃ§Ã£o e teste usam estatÃ­sticas do treino\n",
    "3. **Zero ContaminaÃ§Ã£o**: InformaÃ§Ã£o futura nÃ£o \"vaza\" para o passado\n",
    "4. **Realismo**: Simula cenÃ¡rio real onde sÃ³ temos dados de treino\n",
    "\n",
    "**ğŸ§ª Resultado da PadronizaÃ§Ã£o:**\n",
    "- **Features numÃ©ricas identificadas**: Automaticamente detectadas\n",
    "- **TransformaÃ§Ã£o consistente**: Mesmo scaler para treino/validaÃ§Ã£o/teste\n",
    "- **Escala uniforme**: Todas as features com importÃ¢ncia \"democrÃ¡tica\"\n",
    "\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Com dados perfeitamente preparados, vamos criar modelos baseline para estabelecer nossa \"linha de base\" de performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd01b14",
   "metadata": {},
   "source": [
    "## 2. AnÃ¡lise ExploratÃ³ria dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6933e76",
   "metadata": {},
   "source": [
    "### ğŸ **O que foi feito: Ã‰ o processo de investigar, resumir e visualizar os dados para:**\n",
    "\n",
    "**Marcos de referÃªncia definidos!** Criamos trÃªs \"competidores bÃ¡sicos\" que estabelecem o mÃ­nimo de performance aceitÃ¡vel. Ã‰ como cronometrar corredores amadores antes de trazer os atletas olÃ­mpicos para a pista.\n",
    "\n",
    "**ğŸ¯ Nossos 3 Baselines e Suas Filosofias:**\n",
    "\n",
    "**ğŸ² Baseline Maioria**: \"Chuta sempre a classe mais comum\"\n",
    "- *EstratÃ©gia*: \"Rejeita todo mundo\" (61% accuracy mÃ¡xima possÃ­vel)\n",
    "- *LiÃ§Ã£o*: Mostra o que acontece com modelos preguiÃ§osos\n",
    "\n",
    "**ğŸª Baseline Estratificado**: \"Chuta aleatÃ³rio respeitando proporÃ§Ãµes\"\n",
    "- *EstratÃ©gia*: Usa distribuiÃ§Ã£o real das classes (mais realÃ­stico)\n",
    "- *LiÃ§Ã£o*: Simula \"decisÃµes aleatÃ³rias informadas\"\n",
    "\n",
    "**ğŸ“ˆ Baseline LogÃ­stica Simples**: \"Primeiro modelo real de ML\"\n",
    "- *EstratÃ©gia*: RegressÃ£o logÃ­stica bÃ¡sica sem otimizaÃ§Ã£o\n",
    "- *LiÃ§Ã£o*: Representa \"minimum viable model\"\n",
    "\n",
    "**ğŸ† Meta Estabelecida:**\n",
    "O melhor baseline + 1 desvio padrÃ£o = **nosso padrÃ£o ouro a superar**\n",
    "\n",
    "**ğŸ¯ Por que Baselines SÃ£o Sagrados em ML:**\n",
    "1. **Reality Check**: Evita comemorar modelos \"obviamente ruins\"\n",
    "2. **Contexto de Performance**: F1=0.65 Ã© bom? Depende do baseline!\n",
    "3. **DetecÃ§Ã£o de Problemas**: Se modelo complexo < baseline = algo estÃ¡ errado\n",
    "4. **Justificativa de Complexidade**: Modelo simples pode ser suficiente\n",
    "\n",
    "**ğŸ“Š ValidaÃ§Ã£o Cruzada nos Baselines:**\n",
    "- **MÃºltiplas mediÃ§Ãµes**: 5-fold CV para cada baseline\n",
    "- **EstatÃ­sticas robustas**: MÃ©dia Â± desvio padrÃ£o\n",
    "- **Threshold inteligente**: Melhor baseline + margem de erro\n",
    "\n",
    "**ğŸ§  Filosofia de Humildade:**\n",
    "\"*Before you build a rocket, make sure you can beat a bicycle*\" - Sempre comeÃ§e simples, complique apenas se necessÃ¡rio.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** visualizar estatisca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639919b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise exploratÃ³ria inicial\n",
    "print(\"ğŸ“Š INFORMAÃ‡Ã•ES GERAIS DO DATASET\")\n",
    "print(f\"DimensÃµes: {df_candidatos.shape}\")\n",
    "print(f\"Taxa de aprovaÃ§Ã£o: {df_candidatos['aprovado'].mean():.2%}\")\n",
    "\n",
    "# InformaÃ§Ãµes sobre as colunas\n",
    "print(\"\\nğŸ“‹ INFORMAÃ‡Ã•ES DAS COLUNAS\")\n",
    "print(df_candidatos.info())\n",
    "\n",
    "# EstatÃ­sticas descritivas\n",
    "print(\"\\nğŸ“Š ESTATÃSTICAS DESCRITIVAS\")\n",
    "numeric_cols = df_candidatos.select_dtypes(include=[np.number]).columns\n",
    "print(df_candidatos[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a0d82",
   "metadata": {},
   "source": [
    "### ğŸ“Š **O que foi feito: Raio-X EstatÃ­stico dos Candidatos**\n",
    "\n",
    "**ğŸ” Insights EstatÃ­sticos Principais:**\n",
    "- **Notas de GraduaÃ§Ã£o**: MÃ©dia ~8.2 (candidatos jÃ¡ prÃ©-selecionados pela qualidade)\n",
    "- **ExperiÃªncia Profissional**: VariaÃ§Ã£o 0-15 anos (desde recÃ©m-formados atÃ© experientes)\n",
    "- **PublicaÃ§Ãµes**: DistribuiÃ§Ã£o Poisson (realista - alguns tÃªm muitas, maioria tem poucas)\n",
    "- **PontuaÃ§Ãµes**: Provas ~75, Entrevistas ~80 (entrevistas ligeiramente mais altas)\n",
    "\n",
    "**ğŸ¯ Por que o `.info()` Ã© Nosso Melhor Amigo:**\n",
    "- **Memory Usage**: ~203KB (dataset eficiente, cabe na RAM facilmente)\n",
    "- **Dtypes**: Mix perfeito de int, float e object (dados ricos e variados)\n",
    "- **Non-Null Count**: 2000 em todas - confirmaÃ§Ã£o de integridade total\n",
    "\n",
    "**ğŸ“ˆ Significado das EstatÃ­sticas Descritivas:**\n",
    "O `.describe()` nos mostra que nossos dados tÃªm **distribuiÃ§Ãµes realÃ­sticas**: nÃ£o hÃ¡ valores absurdos, as mÃ©dias fazem sentido para um processo seletivo acadÃªmico, e a variabilidade sugere candidatos genuinamente diversos.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos visualizar esses nÃºmeros! As visualizaÃ§Ãµes transformarÃ£o essas estatÃ­sticas em grÃ¡ficos que facilitam a visualizaÃ§Ã£o em compreensÃ£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391766ad",
   "metadata": {},
   "source": [
    "### ğŸ¤– **O que foi feito: ExecuÃ§Ã£o dos 7 Algoritmos**\n",
    "\n",
    "**ğŸ¯ Logistic Regression**: \"O Estrategista\"\n",
    "- *Personalidade*: RÃ¡pido, interpretÃ¡vel, elegante\n",
    "- *EstratÃ©gia*: CombinaÃ§Ãµes lineares ponderadas\n",
    "\n",
    "**ğŸŒ³ Random Forest**: \"O Democrata\"\n",
    "- *Personalidade*: Robusto, estÃ¡vel, \"wisdom of crowds\"\n",
    "- *EstratÃ©gia*: Voto de mÃºltiplas Ã¡rvores independentes\n",
    "\n",
    "**ğŸš€ Gradient Boosting**: \"O Perfeccionista\"\n",
    "- *Personalidade*: Aprende com erros, iterativo\n",
    "- *EstratÃ©gia*: Corrige erros sequencialmente\n",
    "\n",
    "**âš”ï¸ SVM**: \"O Geometrista\"\n",
    "- *Personalidade*: Encontra fronteiras Ã³timas\n",
    "- *EstratÃ©gia*: Maximiza margens de separaÃ§Ã£o\n",
    "\n",
    "**ğŸ‘¥ KNN**: \"O Social\"\n",
    "- *Personalidade*: \"Me diga com quem andas...\"\n",
    "- *EstratÃ©gia*: Voto dos vizinhos mais prÃ³ximos\n",
    "\n",
    "**ğŸŒ² Decision Tree**: \"O Questionador\"\n",
    "- *Personalidade*: Pergunta sim/nÃ£o sequenciais\n",
    "- *EstratÃ©gia*: Ãrvore de decisÃµes binÃ¡rias\n",
    "\n",
    "**ğŸ² Naive Bayes**: \"O Probabilista\"\n",
    "- *Personalidade*: Assume independÃªncia features\n",
    "- *EstratÃ©gia*: Teorema de Bayes puro\n",
    "\n",
    "**ğŸ† Ranking e Insights:**\n",
    "O ranking por F1-Score CV revela nÃ£o apenas performance, mas **adequaÃ§Ã£o ao problema**. Cada posiÃ§Ã£o conta uma histÃ³ria sobre como diferentes abordagens matemÃ¡ticas \"enxergam\" padrÃµes de aprovaÃ§Ã£o acadÃªmica.\n",
    "\n",
    "**ğŸ”¬ ValidaÃ§Ã£o Cruzada - Nossa Garantia:**\n",
    "- **5 mediÃ§Ãµes independentes** por modelo\n",
    "- **MÃ©dia Â± desvio** para robustez estatÃ­stica\n",
    "- **Evita \"sorte\"**: Performance consistente > performance pontual\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos selecionar nossos top 3 algoritmos e vamos otimizÃ¡-los atravÃ©s de fine-tuning de hiperparÃ¢metros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaÃ§Ã£o da distribuiÃ§Ã£o da variÃ¡vel target\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# GrÃ¡fico de barras\n",
    "target_counts = df_candidatos['aprovado'].value_counts()\n",
    "target_labels = ['Rejeitado', 'Aprovado']\n",
    "colors = ['#ff6b6b', '#4ecdc4']\n",
    "\n",
    "axes[0].bar(target_labels, target_counts.values, color=colors, alpha=0.8)\n",
    "axes[0].set_title('DistribuiÃ§Ã£o de AprovaÃ§Ãµes', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('NÃºmero de Candidatos')\n",
    "\n",
    "# Adicionando percentuais\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    axes[0].text(i, v + 10, f'{v}\\n({v/len(df_candidatos)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# GrÃ¡fico de pizza\n",
    "axes[1].pie(target_counts.values, labels=target_labels, autopct='%1.1f%%', \n",
    "           colors=colors, startangle=90)\n",
    "axes[1].set_title('ProporÃ§Ã£o de AprovaÃ§Ãµes', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54332842",
   "metadata": {},
   "source": [
    "### ğŸ¯ **O que foi feito: CenÃ¡rio de SeleÃ§Ã£o AcadÃªmica**\n",
    "\n",
    "**Primeira visÃ£o!** Nossos grÃ¡ficos revelaram a **distribuiÃ§Ã£o fundamental** do nosso problema de Machine Learning. Ã‰ como olhar para uma fotografia que captura a essÃªncia de um processo seletivo competitivo.\n",
    "\n",
    "**ğŸ“Š InterpretaÃ§Ã£o dos GrÃ¡ficos:**\n",
    "- **GrÃ¡fico de Barras**: Mostra a \"frieza dos nÃºmeros\" - mais rejeitados que aprovados\n",
    "- **GrÃ¡fico de Pizza**: Revela a \"proporÃ§Ã£o visual\" - ~61% vs ~39%\n",
    "- **Cores Escolhidas**: Vermelho (rejeiÃ§Ã£o) vs Verde-azulado (aprovaÃ§Ã£o) - psicologia visual intuitiva\n",
    "\n",
    "**ğŸ¯ Por que Esta DistribuiÃ§Ã£o Ã© Ideal para ML:**\n",
    "1. **NÃ£o Ã© extremamente desbalanceada** (evita viÃ©s do modelo)\n",
    "2. **Reflete realidade acadÃªmica** (processos seletivos sÃ£o competitivos)\n",
    "3. **Permite aprendizado** (classes minoritÃ¡rias ainda tÃªm representaÃ§Ã£o significativa)\n",
    "4. **MÃ©tricas confiÃ¡veis** (F1-Score serÃ¡ mais informativo que Accuracy)\n",
    "\n",
    "**ğŸ§  Insight PsicolÃ³gico:**\n",
    "Esta distribuiÃ§Ã£o conta a histÃ³ria de **sonhos e realidade**: para cada candidato aprovado, hÃ¡ ~1.6 que nÃ£o conseguiu. Ã‰ exatamente isso que nosso modelo precisa aprender - distinguir entre perfis aprovados e rejeitados de forma justa e precisa.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos mergulhar nas distribuiÃ§Ãµes das features individuais para entender o cerne de cada variÃ¡vel preditora!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c4221",
   "metadata": {},
   "source": [
    "### ğŸ›ï¸ **O que foi feito: Treinamneto**\n",
    "\n",
    "**\"LaboratÃ³rio\" de otimizaÃ§Ã£o concluÃ­do!** Pegamos nossos  3 algoritmos e os colocamos em modo treinamento, testando sistematicamente diferentes configuraÃ§Ãµes para extrair sua mÃ¡xima performance.\n",
    "\n",
    "**ğŸ‹ï¸â€â™‚ï¸ Processo de OtimizaÃ§Ã£o Implementado:**\n",
    "\n",
    "**ğŸ” Grid Search SistemÃ¡tico**:\n",
    "- **EstratÃ©gia**: Testa TODAS as combinaÃ§Ãµes possÃ­veis de hiperparÃ¢metros\n",
    "- **ValidaÃ§Ã£o**: Cada combinaÃ§Ã£o testada com 5-fold CV\n",
    "- **MÃ©trica**: F1-Score (nossa mÃ©trica de ouro para este problema)\n",
    "- **Objetivo**: Encontrar configuraÃ§Ã£o \"sweet spot\" perfeita\n",
    "\n",
    "**âš™ï¸ HiperparÃ¢metros Testados por Algoritmo:**\n",
    "\n",
    "**ğŸŒ³ Random Forest**: Ãrvores (50-200), Profundidade (5-âˆ), Amostragem\n",
    "**ğŸš€ Gradient Boosting**: Estimadores (50-200), Learning Rate (0.05-0.2), Profundidade\n",
    "**ğŸ¯ Logistic Regression**: RegularizaÃ§Ã£o C (0.1-100), Penalty (L1/L2)\n",
    "**âš”ï¸ SVM**: ParÃ¢metro C (0.1-10), Kernel (RBF/Poly), Gamma\n",
    "\n",
    "**ğŸ¯ Por que Esta OtimizaÃ§Ã£o Ã© CientÃ­fica:**\n",
    "1. **Busca Exaustiva**: NÃ£o deixa pedra sobre pedra\n",
    "2. **ValidaÃ§Ã£o Cruzada**: Cada teste Ã© estatisticamente robusto\n",
    "3. **PrevenÃ§Ã£o Overfitting**: CV evita \"sorte\" em configuraÃ§Ãµes\n",
    "4. **DocumentaÃ§Ã£o Completa**: Melhores parÃ¢metros sÃ£o preservados\n",
    "\n",
    "**ğŸ† Resultado da OtimizaÃ§Ã£o:**\n",
    "- **Modelo CampeÃ£o**: Identificado cientificamente\n",
    "- **Melhores ParÃ¢metros**: Documentados para reprodutibilidade\n",
    "- **Performance Otimizada**: MÃ¡ximo potencial extraÃ­do\n",
    "- **ConfianÃ§a EstatÃ­stica**: Baseada em mÃºltiplas validaÃ§Ãµes\n",
    "\n",
    "**ğŸ§  Filosofia do Fine-Tuning:**\n",
    "\"*Good artists copy, great artists steal, but data scientists optimize*\" - A diferenÃ§a entre um modelo \"bom\" e \"excelente\" estÃ¡ nos detalhes da configuraÃ§Ã£o.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** testar nosso algoritmo otimizado escolhido no conjunto de teste para avaliaÃ§Ã£o final!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistribuiÃ§Ãµes das variÃ¡veis numÃ©ricas\n",
    "numeric_cols = ['nota_graduacao', 'experiencia_profissional', 'publicacoes', \n",
    "               'projetos_pesquisa', 'pontuacao_prova', 'pontuacao_entrevista', 'idade']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    axes[i].hist(df_candidatos[col], bins=30, alpha=0.7, color='skyblue', density=True)\n",
    "    axes[i].set_title(f'DistribuiÃ§Ã£o: {col.replace(\"_\", \" \").title()}', fontweight='bold')\n",
    "    axes[i].set_xlabel(col.replace(\"_\", \" \").title())\n",
    "    axes[i].set_ylabel('Densidade')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Removendo subplots extras\n",
    "for i in range(len(numeric_cols), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95022bb7",
   "metadata": {},
   "source": [
    "### ğŸ† **O que foi feito: O Resultado**\n",
    "\n",
    "**ğŸ¯ Metodologia do Teste Final:**\n",
    "\n",
    "**ğŸ”„ Treinamento Final Expandido**:\n",
    "- **Dados Utilizados**: Treino + ValidaÃ§Ã£o combinados (80% do dataset total)\n",
    "- **EstratÃ©gia**: MÃ¡xima informaÃ§Ã£o disponÃ­vel para treinamento\n",
    "- **Justificativa**: Simula cenÃ¡rio real onde usamos todos os dados disponÃ­veis\n",
    "\n",
    "**ğŸ§ª Teste Cego\":\n",
    "- **Conjunto Virgem**: 20% nunca \"visto\" pelo modelo\n",
    "- **AvaliaÃ§Ã£o Honesta**: Zero viÃ©s, zero \"trapaÃ§a\"\n",
    "- **MÃ©tricas MÃºltiplas**: Accuracy, Precision, Recall, F1, AUC-ROC\n",
    "\n",
    "**ğŸ“Š AnÃ¡lise de GeneralizaÃ§Ã£o:**\n",
    "- **Gap Calculado**: DiferenÃ§a entre performance CV vs Teste\n",
    "- **InterpretaÃ§Ã£o**: Mede capacidade de generalizar para dados novos\n",
    "- **Thresholds**:\n",
    "  - < 0.02: GeneralizaÃ§Ã£o excelente ğŸ‰\n",
    "  - < 0.05: GeneralizaÃ§Ã£o boa âœ…\n",
    "  - > 0.05: PossÃ­vel overfitting âš ï¸\n",
    "\n",
    "**ğŸ­ O que as MÃ©tricas Revelam:**\n",
    "\n",
    "**Accuracy**: \"Quantos acertos no total?\"\n",
    "**Precision**: \"Dos que previ aprovados, quantos realmente foram?\"\n",
    "**Recall**: \"Dos que foram aprovados, quantos consegui identificar?\"\n",
    "**F1-Score**: \"MÃ©dia harmÃ´nica entre Precision e Recall\" (nossa estrela!)\n",
    "**AUC-ROC**: \"Qualidade discriminativa geral\"\n",
    "\n",
    "**ğŸ§  Filosofia do Teste Final:**\n",
    "\"*The proof of the pudding is in the eating*\" - Todo o trabalho anterior se resume a este momento: o modelo funciona no mundo real?\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos visualizar esses resultados em grÃ¡ficos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c5081",
   "metadata": {},
   "source": [
    "### ğŸ“Š **O que foi feito: VisualizaÃ§Ã£o dos Resultados**\n",
    "\n",
    "**ExposiÃ§Ã£o visual concluÃ­da!** Criamos uma \"galeria de 4 quadros\" que conta visualmente o desempenho do nosso modelo. Cada grÃ¡fico Ã© uma janela para aspectos diferentes da capacidade preditiva.\n",
    "\n",
    "**ğŸ–¼ï¸ AnÃ¡lise da Nossa Galeria:**\n",
    "\n",
    "**ğŸ¨ Quadro 1 - Matriz de ConfusÃ£o**: \"O Espelho da Verdade\"\n",
    "- **Historia**: Mostra exatamente onde acertamos e erramos\n",
    "- **InterpretaÃ§Ã£o**: Diagonal = acertos, off-diagonal = confusÃµes\n",
    "- **Insight**: Revela se erramos mais rejeitando bons candidatos ou aprovando ruins\n",
    "\n",
    "**ğŸ“ˆ Quadro 2 - Curva ROC**: \"A DanÃ§a da DiscriminaÃ§Ã£o\"\n",
    "- **HistÃ³ria**: Quanto melhor que o chute aleatÃ³rio somos?\n",
    "- **InterpretaÃ§Ã£o**: Ãrea sob curva (AUC) mede qualidade discriminativa\n",
    "- **Insight**: Curva prÃ³xima ao canto superior esquerdo = excelente\n",
    "\n",
    "**ğŸ“Š Quadro 3 - MÃ©tricas Comparadas**: \"O Painel de Performance\"\n",
    "- **HistÃ³ria**: VisÃ£o panorÃ¢mica de todas as mÃ©tricas importantes\n",
    "- **InterpretaÃ§Ã£o**: Altura das barras = qualidade de cada aspecto\n",
    "- **Insight**: Mostra se somos \"bem-arredondados\" ou especialistas em algo\n",
    "\n",
    "**ğŸ¯ Quadro 4 - DistribuiÃ§Ã£o de Probabilidades**: \"O Mapa da ConfianÃ§a\"\n",
    "- **HistÃ³ria**: QuÃ£o confiante o modelo estÃ¡ em suas decisÃµes?\n",
    "- **InterpretaÃ§Ã£o**: SeparaÃ§Ã£o clara entre histogramas = boa discriminaÃ§Ã£o\n",
    "- **Insight**: SobreposiÃ§Ã£o = incerteza, separaÃ§Ã£o = confianÃ§a\n",
    "\n",
    "**ğŸ­ Por que VisualizaÃ§Ã£o Ã© Crucial em ML:**\n",
    "1. **ComunicaÃ§Ã£o**: Stakeholders entendem grÃ¡ficos > nÃºmeros\n",
    "2. **DiagnÃ³stico**: Problemas ficam visÃ­veis instantaneamente\n",
    "3. **ConfianÃ§a**: Ver padrÃµes aumenta credibilidade do modelo\n",
    "4. **Insights**: GrÃ¡ficos revelam nuances que mÃ©tricas escondem\n",
    "\n",
    "**ğŸ§  Arte + CiÃªncia:**\n",
    "\"*A picture is worth a thousand metrics*\" - NÃºmeros dizem o que, grÃ¡ficos dizem por que e como.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos descobrir quais features nosso modelo considera mais importantes para tomar decisÃµes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdaf70",
   "metadata": {},
   "source": [
    "## 3. PrÃ©-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9d2a9",
   "metadata": {},
   "source": [
    "### ğŸ” **O que foi feito: AnÃ¡lise Modelo**\n",
    "\n",
    "**AnÃ¡lise concluÃ­da!** Acabamos de \"abrir a mente\" do nosso modelo para entender exatamente quais caracterÃ­sticas ele considera mais importantes ao decidir sobre aprovaÃ§Ãµes. Ã‰ como descobrir os critÃ©rios secretos de um comitÃª de seleÃ§Ã£o.\n",
    "\n",
    "**ğŸ§  Duas Abordagens de AnÃ¡lise Implementadas:**\n",
    "\n",
    "**ğŸŒ³ Feature Importances Nativas** (para modelos tree-based):\n",
    "- **MÃ©todo**: Baseado na reduÃ§Ã£o de impureza em cada split\n",
    "- **InterpretaÃ§Ã£o**: Quanto cada feature \"purifica\" as decisÃµes\n",
    "- **Vantagem**: RÃ¡pido e diretamente do algoritmo\n",
    "\n",
    "**ğŸ² Permutation Importance** (para qualquer modelo):\n",
    "- **MÃ©todo**: Embaralha feature e mede perda de performance\n",
    "- **InterpretaÃ§Ã£o**: \"Se eu removesse esta info, quÃ£o pior ficaria?\"\n",
    "- **Vantagem**: Funciona universalmente, mede impacto real\n",
    "\n",
    "**ğŸ† Top Features Reveladas:**\n",
    "O ranking de importÃ¢ncia revela a **hierarquia de decisÃ£o** do modelo:\n",
    "- **Features acadÃªmicas** dominam? (notas, pontuaÃ§Ãµes)\n",
    "- **Features experienciais** sÃ£o relevantes? (publicaÃ§Ãµes, experiÃªncia)\n",
    "- **Features categÃ³ricas** fazem diferenÃ§a? (programa, instituiÃ§Ã£o)\n",
    "- **Features engineered** funcionaram? (nossa criatividade validada)\n",
    "\n",
    "**ğŸ“Š VisualizaÃ§Ã£o Horizontal:**\n",
    "- **Barras horizontais**: FÃ¡cil leitura dos nomes de features\n",
    "- **OrdenaÃ§Ã£o decrescente**: Do mais importante ao menos\n",
    "- **Top 15**: Foco nas features que realmente importam\n",
    "\n",
    "**ğŸ¯ Por que Esta AnÃ¡lise Ã© Fundamental:**\n",
    "1. **Explicabilidade**: Podemos explicar decisÃµes para stakeholders\n",
    "2. **ValidaÃ§Ã£o**: ImportÃ¢ncias fazem sentido no contexto?\n",
    "3. **OtimizaÃ§Ã£o**: Features irrelevantes podem ser removidas\n",
    "4. **Insights de NegÃ³cio**: Revela critÃ©rios \"ocultos\" de seleÃ§Ã£o\n",
    "\n",
    "**ğŸ§  Filosofia da TransparÃªncia:**\n",
    "\"*Black boxes are for airplanes, not for academic selection*\" - DecisÃµes importantes precisam ser explicÃ¡veis e auditÃ¡veis.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** relatÃ³rio final abrangente e conclusÃµes prÃ¡ticas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreparaÃ§Ã£o e limpeza dos dados\n",
    "df_clean = df_candidatos.copy()\n",
    "\n",
    "print(\"ğŸ§¹ LIMPEZA DOS DADOS\")\n",
    "print(f\"Dataset original: {df_clean.shape}\")\n",
    "\n",
    "# Verificar valores ausentes\n",
    "missing_values = df_clean.isnull().sum().sum()\n",
    "print(f\"Valores ausentes: {missing_values}\")\n",
    "\n",
    "# Verificar duplicatas\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"Duplicatas: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"Duplicatas removidas. Novo shape: {df_clean.shape}\")\n",
    "\n",
    "print(f\"âœ… Dataset limpo: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c402b6",
   "metadata": {},
   "source": [
    "### ğŸ“ **RelatÃ³rio: De Dados Brutos a Insights AcionÃ¡veis**\n",
    "\n",
    "**O que foi feito!** Acabamos de completar a transformaÃ§Ã£o de  2000 perfis de candidatos em um sistema inteligente capaz de predizer aprovaÃ§Ãµes acadÃªmicas.\n",
    "\n",
    "**ğŸ“š O que foi feito - Passo a Passo:**\n",
    "\n",
    "**ğŸ Passo 1**: PreparaÃ§Ã£o do ambiente  - Importamos ferramentas e definimos o problema\n",
    "**ğŸ“Š Passo 2**: Carregando o dataset- Carregamos e exploramos 2000 candidatos\n",
    "**ğŸ§¹ Passo 3**: Limpeza e OrganizaÃ§Ã£o - Preparamos dados para anÃ¡lise\n",
    "**âš™ï¸ Passo 4**: Novas features - Criamos novas features inteligentes\n",
    "**ğŸ”¢ Passo 5**: Converter - Convertemos categorias para linguagem ML\n",
    "**ğŸ“Š Passo 6**: Dividir para conquistar - Dividimos dados para treino/validaÃ§Ã£o/teste\n",
    "**ğŸ Passo 7**: estabelecer Baselines - Estabelecemos padrÃµes mÃ­nimos\n",
    "**ğŸ¤– Passo 8**: ExecuÃ§Ã£po dos 7 Algoritmos - Testamos diferentes abordagens ML\n",
    "**ğŸ›ï¸ Passo 9**: OtimizaÃ§Ã£o - Fine-tuning para mÃ¡xima performance\n",
    "**ğŸ† Passo 10**: teste final - Teste final nos dados limpos\n",
    "**ğŸ” Passo 11**: AnÃ¡lise dos modelos - AnÃ¡lise de importÃ¢ncia de features\n",
    "\n",
    "**ğŸ¯ Conquistas AlcanÃ§adas:**\n",
    "- âœ… **Modelo Funcional**: F1-Score competitivo para o problema\n",
    "- âœ… **Pipeline Completo**: Do raw data ao modelo em produÃ§Ã£o\n",
    "- âœ… **Metodologia CientÃ­fica**: ValidaÃ§Ã£o cruzada e teste independente\n",
    "- âœ… **Interpretabilidade**: Sabemos POR QUE o modelo decide\n",
    "- âœ… **Reprodutibilidade**: Qualquer pessoa pode replicar nossos resultados\n",
    "- âœ… **DocumentaÃ§Ã£o Rica**: Cada etapa explicada e justificada\n",
    "\n",
    "**ğŸš€ Impacto e AplicaÃ§Ã£o PrÃ¡tica:**\n",
    "Nosso modelo nÃ£o Ã© apenas nÃºmeros - Ã© uma **ferramenta de apoio Ã  decisÃ£o** que pode:\n",
    "- Acelerar triagem inicial de candidatos\n",
    "- Identificar perfis promissores sistematicamente\n",
    "- Reduzir viÃ©s humano em avaliaÃ§Ãµes\n",
    "- Fornecer critÃ©rios objetivos e auditÃ¡veis\n",
    "\n",
    "**ğŸ§  LiÃ§Ãµes Aprendidas:**\n",
    "1. **Dados de qualidade > algoritmos complexos**\n",
    "2. **ValidaÃ§Ã£o rigorosa > performance pontual**\n",
    "3. **Interpretabilidade > precisÃ£o absoluta**\n",
    "4. **Metodologia > resultados isolados**\n",
    "\n",
    "**ğŸŠ ConclusÃ£o Final:**\n",
    "Transformamos dados extraidos de uma dataset em conhecimento, dados em insights, e cÃ³digo em impacto real. Esta Ã© a essÃªncia da CiÃªncia de Dados - usar matemÃ¡tica e programaÃ§Ã£o para resolver problemas humanos reais!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c239328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"âš™ï¸ ENGENHARIA DE FEATURES\")\n",
    "df_processed = df_clean.copy()\n",
    "\n",
    "# Novas features\n",
    "df_processed['pontuacao_media'] = (df_processed['pontuacao_prova'] + df_processed['pontuacao_entrevista']) / 2\n",
    "df_processed['produtividade_academica'] = (df_processed['publicacoes'] * 2 + df_processed['projetos_pesquisa']) / (df_processed['experiencia_profissional'] + 1)\n",
    "df_processed['score_desempenho'] = (0.4 * df_processed['nota_graduacao'] + 0.3 * df_processed['pontuacao_prova'] / 10 + 0.3 * df_processed['pontuacao_entrevista'] / 10)\n",
    "df_processed['log_renda_familiar'] = np.log1p(df_processed['renda_familiar'])\n",
    "\n",
    "# Features binÃ¡rias\n",
    "df_processed['tem_publicacoes'] = (df_processed['publicacoes'] > 0).astype(int)\n",
    "df_processed['tem_projetos'] = (df_processed['projetos_pesquisa'] > 0).astype(int)\n",
    "df_processed['experiencia_alta'] = (df_processed['experiencia_profissional'] > df_processed['experiencia_profissional'].median()).astype(int)\n",
    "\n",
    "print(f\"âœ… Features criadas. Shape atual: {df_processed.shape}\")\n",
    "print(\"Novas features:\")\n",
    "new_features = ['pontuacao_media', 'produtividade_academica', 'score_desempenho', 'log_renda_familiar', 'tem_publicacoes', 'tem_projetos', 'experiencia_alta']\n",
    "for feat in new_features:\n",
    "    print(f\"  â€¢ {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cdade",
   "metadata": {},
   "source": [
    "### âš™ï¸ **O que foi feito: Engenharia de Features**\n",
    "\n",
    "**AÃ§Ã£o!** Acabamos de atuar como \"arquitetos de informaÃ§Ã£o\", criando 7 novas features derivadas que podem revelar padrÃµes ocultos nos dados originais. \n",
    "\n",
    "**ğŸ—ï¸ Novas Features Criadas e Suas HistÃ³rias:**\n",
    "\n",
    "**ğŸ“Š `pontuacao_media`**: Combina prova + entrevista\n",
    "- *Filosofia*: Performance acadÃªmica geral mais robusta que medidas individuais\n",
    "\n",
    "**ğŸ¯ `produtividade_academica`**: (PublicaÃ§ÃµesÃ—2 + Projetos) / (ExperiÃªncia + 1)\n",
    "- *Filosofia*: Mede \"eficiÃªncia de pesquisa\" - quÃ£o produtivo Ã© o candidato por ano de experiÃªncia\n",
    "\n",
    "**â­ `score_desempenho`**: Weighted average de notas e pontuaÃ§Ãµes\n",
    "- *Filosofia*: \"Ãndice de ExcelÃªncia\" que o comitÃª de seleÃ§Ã£o mentalmente calcula\n",
    "\n",
    "**ğŸ’° `log_renda_familiar`**: TransformaÃ§Ã£o logarÃ­tmica da renda\n",
    "- *Filosofia*: Normaliza distribuiÃ§Ã£o assimÃ©trica (R$1Kâ†’10K Ã© diferente de R$10Kâ†’20K)\n",
    "\n",
    "**ğŸ”¢ Features BinÃ¡rias** (`tem_publicacoes`, `tem_projetos`, `experiencia_alta`):\n",
    "- *Filosofia*: Ã€s vezes \"ter ou nÃ£o ter\" Ã© mais importante que \"quanto\"\n",
    "\n",
    "**ğŸ§  Por que Feature Engineering Ã© MÃ¡gica:**\n",
    "- **ExpÃµe RelaÃ§Ãµes**: Combina informaÃ§Ãµes de formas que algoritmos ML \"entendem\" melhor\n",
    "- **Reduz Complexidade**: TransformaÃ§Ãµes tornam padrÃµes mais evidentes\n",
    "- **Imita CogniÃ§Ã£o Humana**: Como avaliadores humanos processam informaÃ§Ãµes\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos transformar variÃ¡veis categÃ³ricas em formato numÃ©rico que nossos algoritmos conseguem processar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas\n",
    "print(\"ğŸ·ï¸ CODIFICAÃ‡ÃƒO DE VARIÃVEIS CATEGÃ“RICAS\")\n",
    "\n",
    "categorical_features = ['programa', 'nivel_pretendido', 'tipo_instituicao_origem', \n",
    "                       'regiao_origem', 'modalidade_candidatura', 'ensino_ingles']\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_processed, columns=categorical_features, prefix=categorical_features)\n",
    "\n",
    "print(f\"âœ… Encoding aplicado. Shape final: {df_encoded.shape}\")\n",
    "\n",
    "# Separar features e target\n",
    "X = df_encoded.drop('aprovado', axis=1)\n",
    "y = df_encoded['aprovado']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"DistribuiÃ§Ã£o do target: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177aaa65",
   "metadata": {},
   "source": [
    "## 4. DivisÃ£o dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DivisÃ£o dos dados em treino, validaÃ§Ã£o e teste\n",
    "print(\"ğŸ“Š DIVISÃƒO DOS DADOS\")\n",
    "\n",
    "# Primeira divisÃ£o: separar teste (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Segunda divisÃ£o: separar treino (60%) e validaÃ§Ã£o (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"ValidaÃ§Ã£o: {X_val.shape[0]} amostras ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Teste: {X_test.shape[0]} amostras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# ConfiguraÃ§Ã£o da validaÃ§Ã£o cruzada\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "print(f\"\\nğŸ”„ ValidaÃ§Ã£o cruzada configurada: Stratified K-Fold (k=5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e32eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PadronizaÃ§Ã£o das features\n",
    "print(\"âš–ï¸ PADRONIZAÃ‡ÃƒO DAS FEATURES\")\n",
    "\n",
    "# Identificar features numÃ©ricas\n",
    "numeric_features_final = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Criar e ajustar o scaler apenas no conjunto de treino\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Aplicar padronizaÃ§Ã£o\n",
    "X_train_scaled[numeric_features_final] = scaler.fit_transform(X_train[numeric_features_final])\n",
    "X_val_scaled[numeric_features_final] = scaler.transform(X_val[numeric_features_final])\n",
    "X_test_scaled[numeric_features_final] = scaler.transform(X_test[numeric_features_final])\n",
    "\n",
    "print(f\"âœ… {len(numeric_features_final)} features numÃ©ricas padronizadas\")\n",
    "print(\"âœ… Scaler ajustado apenas no treino (evita vazamento)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976aba6",
   "metadata": {},
   "source": [
    "## 5. Modelos Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImplementaÃ§Ã£o de modelos baseline\n",
    "print(\"ğŸ MODELOS BASELINE\")\n",
    "\n",
    "def avaliar_modelo(modelo, X_train, y_train, X_val, y_val, nome_modelo):\n",
    "    \"\"\"FunÃ§Ã£o para avaliar modelos\"\"\"\n",
    "    # Treinar modelo\n",
    "    start_time = time.time()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # PrediÃ§Ãµes\n",
    "    y_pred = modelo.predict(X_val)\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # ValidaÃ§Ã£o cruzada\n",
    "    cv_scores = cross_val_score(modelo, X_train, y_train, cv=cv_strategy, scoring='f1')\n",
    "    \n",
    "    return {\n",
    "        'modelo': nome_modelo,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'cv_f1_mean': cv_scores.mean(),\n",
    "        'cv_f1_std': cv_scores.std(),\n",
    "        'train_time': train_time\n",
    "    }\n",
    "\n",
    "# Modelos baseline\n",
    "baseline_results = []\n",
    "\n",
    "# 1. Baseline - Maioria\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "result_majority = avaliar_modelo(dummy_majority, X_train_scaled, y_train, X_val_scaled, y_val, 'Baseline_Maioria')\n",
    "baseline_results.append(result_majority)\n",
    "\n",
    "# 2. Baseline - Estratificada\n",
    "dummy_stratified = DummyClassifier(strategy='stratified', random_state=RANDOM_STATE)\n",
    "result_stratified = avaliar_modelo(dummy_stratified, X_train_scaled, y_train, X_val_scaled, y_val, 'Baseline_Estratificada')\n",
    "baseline_results.append(result_stratified)\n",
    "\n",
    "# 3. Baseline - Logistic Regression Simples\n",
    "lr_simple = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "result_lr_simple = avaliar_modelo(lr_simple, X_train_scaled, y_train, X_val_scaled, y_val, 'Baseline_LogReg')\n",
    "baseline_results.append(result_lr_simple)\n",
    "\n",
    "# Resultados dos baselines\n",
    "df_baseline_results = pd.DataFrame(baseline_results)\n",
    "print(\"\\nğŸ“Š RESULTADOS DOS BASELINES:\")\n",
    "print(df_baseline_results[['modelo', 'accuracy', 'f1_score', 'cv_f1_mean']].round(4))\n",
    "\n",
    "# Melhor baseline\n",
    "best_baseline = df_baseline_results.loc[df_baseline_results['cv_f1_mean'].idxmax()]\n",
    "baseline_threshold = best_baseline['cv_f1_mean'] + best_baseline['cv_f1_std']\n",
    "\n",
    "print(f\"\\nğŸ† Melhor baseline: {best_baseline['modelo']}\")\n",
    "print(f\"ğŸ¯ Meta para modelos avanÃ§ados: F1-Score > {baseline_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4dc6d9",
   "metadata": {},
   "source": [
    "### ğŸ **O que foi feito: Iniciando baselines**\n",
    "\n",
    "**ğŸ¯ Nossos 3 Baselines e Suas Filosofias:**\n",
    "\n",
    "**ğŸ² Baseline Maioria**: \"Chuta sempre a classe mais comum\"\n",
    "- *EstratÃ©gia*: \"Rejeita todo mundo\" (61% accuracy mÃ¡xima possÃ­vel)\n",
    "- *LiÃ§Ã£o*: Mostra o que acontece com modelos preguiÃ§osos\n",
    "\n",
    "**ğŸª Baseline Estratificado**: \"Chuta aleatÃ³rio respeitando proporÃ§Ãµes\"\n",
    "- *EstratÃ©gia*: Usa distribuiÃ§Ã£o real das classes (mais realÃ­stico)\n",
    "- *LiÃ§Ã£o*: Simula \"decisÃµes aleatÃ³rias informadas\"\n",
    "\n",
    "**ğŸ“ˆ Baseline LogÃ­stica Simples**: \"Primeiro modelo real de ML\"\n",
    "- *EstratÃ©gia*: RegressÃ£o logÃ­stica bÃ¡sica sem otimizaÃ§Ã£o\n",
    "- *LiÃ§Ã£o*: Representa \"minimum viable model\"\n",
    "\n",
    "**ğŸ† Meta Estabelecida:**\n",
    "O melhor baseline + 1 desvio padrÃ£o = **nosso padrÃ£o ouro a superar**\n",
    "\n",
    "**ğŸ¯ Por que Baselines SÃ£o Sagrados em ML:**\n",
    "1. **Reality Check**: Evita comemorar modelos \"obviamente ruins\"\n",
    "2. **Contexto de Performance**: F1=0.65 Ã© bom? Depende do baseline!\n",
    "3. **DetecÃ§Ã£o de Problemas**: Se modelo complexo < baseline = algo estÃ¡ errado\n",
    "4. **Justificativa de Complexidade**: Modelo simples pode ser suficiente\n",
    "\n",
    "**ğŸ§  Filosofia de Humildade:**\n",
    "\"*Before you build a rocket, make sure you can beat a bicycle*\" - Sempre comece simples, complique apenas se necessÃ¡rio.\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Agora vamos soltar nossos \"7 gladiadores\" de Machine Learning na arena para uma batalha Ã©pica!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd7447",
   "metadata": {},
   "source": [
    "## 6. Treinamento de Modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeleÃ§Ã£o e treinamento de algoritmos de ML\n",
    "print(\"ğŸ¤– ALGORITMOS DE MACHINE LEARNING\")\n",
    "\n",
    "algorithms = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "def avaliar_modelo_completo(modelo, X_train, y_train, X_val, y_val, nome_modelo, cv_strategy):\n",
    "    \"\"\"AvaliaÃ§Ã£o completa com mÃºltiplas mÃ©tricas\"\"\"\n",
    "    # Treinar modelo\n",
    "    start_time = time.time()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # PrediÃ§Ãµes\n",
    "    y_pred = modelo.predict(X_val)\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    \n",
    "    # AUC-ROC\n",
    "    try:\n",
    "        y_proba = modelo.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_proba)\n",
    "    except:\n",
    "        auc = np.nan\n",
    "    \n",
    "    # ValidaÃ§Ã£o cruzada\n",
    "    cv_scores = cross_val_score(modelo, X_train, y_train, cv=cv_strategy, scoring='f1')\n",
    "    \n",
    "    return {\n",
    "        'modelo': nome_modelo,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc,\n",
    "        'cv_f1_mean': cv_scores.mean(),\n",
    "        'cv_f1_std': cv_scores.std(),\n",
    "        'train_time': train_time,\n",
    "        'trained_model': modelo\n",
    "    }\n",
    "\n",
    "# Avaliar todos os modelos\n",
    "model_results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in algorithms.items():\n",
    "    print(f\"ğŸ”„ Avaliando {name}...\")\n",
    "    resultado = avaliar_modelo_completo(\n",
    "        model, X_train_scaled, y_train, X_val_scaled, y_val, name, cv_strategy\n",
    "    )\n",
    "    model_results.append(resultado)\n",
    "    trained_models[name] = resultado['trained_model']\n",
    "\n",
    "# Resultados\n",
    "df_model_results = pd.DataFrame(model_results)\n",
    "print(\"\\nğŸ“Š RESULTADOS DOS MODELOS:\")\n",
    "comparison_cols = ['modelo', 'cv_f1_mean', 'cv_f1_std', 'accuracy', 'auc_roc']\n",
    "print(df_model_results[comparison_cols].round(4))\n",
    "\n",
    "# Ranking dos modelos\n",
    "df_sorted = df_model_results.sort_values('cv_f1_mean', ascending=False)\n",
    "print(\"\\nğŸ† RANKING DOS MODELOS (por F1-Score CV):\")\n",
    "for i, (idx, row) in enumerate(df_sorted.iterrows(), 1):\n",
    "    print(f\"   {i}Âº {row['modelo']}: F1 = {row['cv_f1_mean']:.4f} (Â±{row['cv_f1_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f85fce",
   "metadata": {},
   "source": [
    "### ğŸ¤– **O que foi feito: ExecuÃ§Ã£o 7 Algoritmos**\n",
    "\n",
    "\n",
    "\n",
    "**ğŸŸï¸ Perfil:**\n",
    "\n",
    "**ğŸ¯ Logistic Regression**: \"O Estrategista\"\n",
    "- *Personalidade*: RÃ¡pido, interpretÃ¡vel, elegante\n",
    "- *EstratÃ©gia*: CombinaÃ§Ãµes lineares ponderadas\n",
    "\n",
    "**ğŸŒ³ Random Forest**: \"O Democrata\"\n",
    "- *Personalidade*: Robusto, estÃ¡vel, \"wisdom of crowds\"\n",
    "- *EstratÃ©gia*: Voto de mÃºltiplas Ã¡rvores independentes\n",
    "\n",
    "**ğŸš€ Gradient Boosting**: \"O Perfeccionista\"\n",
    "- *Personalidade*: Aprende com erros, iterativo\n",
    "- *EstratÃ©gia*: Corrige erros sequencialmente\n",
    "\n",
    "**âš”ï¸ SVM**: \"O Geometrista\"\n",
    "- *Personalidade*: Encontra fronteiras Ã³timas\n",
    "- *EstratÃ©gia*: Maximiza margens de separaÃ§Ã£o\n",
    "\n",
    "**ğŸ‘¥ KNN**: \"O Social\"\n",
    "- *Personalidade*: \"Me diga com quem andas...\"\n",
    "- *EstratÃ©gia*: Voto dos vizinhos mais prÃ³ximos\n",
    "\n",
    "**ğŸŒ² Decision Tree**: \"O Questionador\"\n",
    "- *Personalidade*: Pergunta sim/nÃ£o sequenciais\n",
    "- *EstratÃ©gia*: Ãrvore de decisÃµes binÃ¡rias\n",
    "\n",
    "**ğŸ² Naive Bayes**: \"O Probabilista\"\n",
    "- *Personalidade*: Assume independÃªncia features\n",
    "- *EstratÃ©gia*: Teorema de Bayes puro\n",
    "\n",
    "**ğŸ† Ranking e Insights:**\n",
    "O ranking por F1-Score CV revela nÃ£o apenas performance, mas **adequaÃ§Ã£o ao problema**. Cada posiÃ§Ã£o conta uma histÃ³ria sobre como diferentes abordagens matemÃ¡ticas \"enxergam\" padrÃµes de aprovaÃ§Ã£o acadÃªmica.\n",
    "\n",
    "**ğŸ”¬ ValidaÃ§Ã£o Cruzada - Nossa Garantia:**\n",
    "- **5 mediÃ§Ãµes independentes** por modelo\n",
    "- **MÃ©dia Â± desvio** para robustez estatÃ­stica\n",
    "- **Evita \"sorte\"**: Performance consistente > performance pontual\n",
    "\n",
    "**ğŸƒâ€â™‚ï¸ PrÃ³ximo Passo:** Vamos pegar nossos top 3 campeÃµes e otimizar seus \"superpoderes\" atravÃ©s de fine-tuning de hiperparÃ¢metros!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff708a",
   "metadata": {},
   "source": [
    "## 7. OtimizaÃ§Ã£o de HiperparÃ¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87023d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OtimizaÃ§Ã£o de hiperparÃ¢metros dos melhores modelos\n",
    "print(\"ğŸ›ï¸ OTIMIZAÃ‡ÃƒO DE HIPERPARÃ‚METROS\")\n",
    "\n",
    "# Selecionar top 3 modelos\n",
    "top_models = df_sorted.head(3)['modelo'].tolist()\n",
    "print(f\"Top 3 modelos selecionados: {top_models}\")\n",
    "\n",
    "# Grids de hiperparÃ¢metros\n",
    "hyperparameter_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Otimizar modelos selecionados\n",
    "optimized_results = []\n",
    "\n",
    "for model_name in top_models:\n",
    "    if model_name in hyperparameter_grids:\n",
    "        print(f\"\\nğŸ” Otimizando {model_name}...\")\n",
    "        \n",
    "        # Modelo base\n",
    "        base_model = algorithms[model_name]\n",
    "        param_grid = hyperparameter_grids[model_name]\n",
    "        \n",
    "        # Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv_strategy,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        result = {\n",
    "            'modelo': model_name,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'best_estimator': grid_search.best_estimator_\n",
    "        }\n",
    "        \n",
    "        optimized_results.append(result)\n",
    "        \n",
    "        print(f\"âœ“ Melhor F1-Score: {result['best_score']:.4f}\")\n",
    "        print(f\"âœ“ Melhores parÃ¢metros: {result['best_params']}\")\n",
    "\n",
    "# Identificar melhor modelo otimizado\n",
    "if optimized_results:\n",
    "    best_optimized = max(optimized_results, key=lambda x: x['best_score'])\n",
    "    final_model = best_optimized['best_estimator']\n",
    "    \n",
    "    print(f\"\\nğŸ† MELHOR MODELO APÃ“S OTIMIZAÃ‡ÃƒO:\")\n",
    "    print(f\"   Modelo: {best_optimized['modelo']}\")\n",
    "    print(f\"   F1-Score: {best_optimized['best_score']:.4f}\")\n",
    "    print(f\"   ParÃ¢metros: {best_optimized['best_params']}\")\n",
    "else:\n",
    "    # Se nÃ£o houver otimizaÃ§Ã£o, usar o melhor modelo original\n",
    "    best_model_name = df_sorted.iloc[0]['modelo']\n",
    "    final_model = trained_models[best_model_name]\n",
    "    print(f\"\\nğŸ† MELHOR MODELO (sem otimizaÃ§Ã£o): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3e6b9",
   "metadata": {},
   "source": [
    "## 8. AvaliaÃ§Ã£o Final no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4233861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AvaliaÃ§Ã£o final no conjunto de teste\n",
    "print(\"ğŸ† AVALIAÃ‡ÃƒO FINAL NO CONJUNTO DE TESTE\")\n",
    "\n",
    "# Treinar modelo final com treino + validaÃ§Ã£o\n",
    "X_train_final = pd.concat([X_train_scaled, X_val_scaled], ignore_index=True)\n",
    "y_train_final = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "print(f\"Dataset final de treinamento: {X_train_final.shape}\")\n",
    "\n",
    "# Treinar modelo final\n",
    "start_time = time.time()\n",
    "final_model.fit(X_train_final, y_train_final)\n",
    "final_train_time = time.time() - start_time\n",
    "\n",
    "# PrediÃ§Ãµes no teste\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "y_test_proba = final_model.predict_proba(X_test_scaled)[:, 1] if hasattr(final_model, 'predict_proba') else None\n",
    "\n",
    "# MÃ©tricas finais\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba) if y_test_proba is not None else None\n",
    "\n",
    "print(f\"\\nğŸ¯ MÃ‰TRICAS FINAIS DE TESTE:\")\n",
    "print(f\"   â€¢ Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   â€¢ Precision: {test_precision:.4f}\")\n",
    "print(f\"   â€¢ Recall: {test_recall:.4f}\")\n",
    "print(f\"   â€¢ F1-Score: {test_f1:.4f}\")\n",
    "if test_auc:\n",
    "    print(f\"   â€¢ AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusÃ£o\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"\\nğŸ“Š MATRIZ DE CONFUSÃƒO:\")\n",
    "print(cm_test)\n",
    "\n",
    "# AnÃ¡lise de generalizaÃ§Ã£o\n",
    "if 'best_optimized' in locals():\n",
    "    cv_f1_score = best_optimized['best_score']\n",
    "else:\n",
    "    cv_f1_score = df_sorted.iloc[0]['cv_f1_mean']\n",
    "\n",
    "generalization_gap = test_f1 - cv_f1_score\n",
    "print(f\"\\nğŸ“ˆ ANÃLISE DE GENERALIZAÃ‡ÃƒO:\")\n",
    "print(f\"   â€¢ F1-Score ValidaÃ§Ã£o Cruzada: {cv_f1_score:.4f}\")\n",
    "print(f\"   â€¢ F1-Score Teste: {test_f1:.4f}\")\n",
    "print(f\"   â€¢ Gap de GeneralizaÃ§Ã£o: {generalization_gap:+.4f}\")\n",
    "\n",
    "if abs(generalization_gap) < 0.02:\n",
    "    print(f\"   âœ… Excelente generalizaÃ§Ã£o!\")\n",
    "elif abs(generalization_gap) < 0.05:\n",
    "    print(f\"   âœ… Boa generalizaÃ§Ã£o\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ PossÃ­vel overfitting - investigar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaÃ§Ã£o final dos resultados\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Matriz de ConfusÃ£o\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
    "axes[0,0].set_title('Matriz de ConfusÃ£o - Conjunto de Teste')\n",
    "axes[0,0].set_xlabel('Predito')\n",
    "axes[0,0].set_ylabel('Real')\n",
    "\n",
    "# 2. Curva ROC\n",
    "if y_test_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {test_auc:.3f})')\n",
    "    axes[0,1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    axes[0,1].set_xlabel('Taxa de Falsos Positivos')\n",
    "    axes[0,1].set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "    axes[0,1].set_title('Curva ROC - Conjunto de Teste')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[0,1].text(0.5, 0.5, 'ROC nÃ£o disponÃ­vel\\npara este modelo', \n",
    "                  ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "\n",
    "# 3. ComparaÃ§Ã£o de MÃ©tricas\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "test_scores = [test_accuracy, test_precision, test_recall, test_f1]\n",
    "\n",
    "axes[1,0].bar(metrics, test_scores, alpha=0.8, color='skyblue')\n",
    "axes[1,0].set_ylabel('Score')\n",
    "axes[1,0].set_title('MÃ©tricas no Conjunto de Teste')\n",
    "axes[1,0].set_ylim(0, 1)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(test_scores):\n",
    "    axes[1,0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. DistribuiÃ§Ã£o de Probabilidades\n",
    "if y_test_proba is not None:\n",
    "    prob_rejected = y_test_proba[y_test == 0]\n",
    "    prob_approved = y_test_proba[y_test == 1]\n",
    "    \n",
    "    axes[1,1].hist(prob_rejected, alpha=0.7, bins=20, label='Rejeitados', color='red')\n",
    "    axes[1,1].hist(prob_approved, alpha=0.7, bins=20, label='Aprovados', color='green')\n",
    "    axes[1,1].set_xlabel('Probabilidade de AprovaÃ§Ã£o')\n",
    "    axes[1,1].set_ylabel('FrequÃªncia')\n",
    "    axes[1,1].set_title('DistribuiÃ§Ã£o das Probabilidades Preditas')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Probabilidades nÃ£o disponÃ­veis\\npara este modelo', \n",
    "                  ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67b530",
   "metadata": {},
   "source": [
    "## 9. AnÃ¡lise de ImportÃ¢ncia das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise de importÃ¢ncia das features\n",
    "print(\"ğŸ” ANÃLISE DE IMPORTÃ‚NCIA DAS FEATURES\")\n",
    "\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    print(f\"âœ… Modelo suporta anÃ¡lise de importÃ¢ncia nativa\")\n",
    "    \n",
    "    # Obter importÃ¢ncias\n",
    "    feature_importance = final_model.feature_importances_\n",
    "    feature_names = X_train_final.columns.tolist()\n",
    "    \n",
    "    # DataFrame com importÃ¢ncias\n",
    "    df_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP 15 FEATURES MAIS IMPORTANTES:\")\n",
    "    for i, (_, row) in enumerate(df_importance.head(15).iterrows(), 1):\n",
    "        print(f\"   {i:2d}Âº {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # VisualizaÃ§Ã£o das importÃ¢ncias\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = df_importance.head(15)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('ImportÃ¢ncia da Feature')\n",
    "    plt.title(f'Top 15 Features Mais Importantes - {type(final_model).__name__}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(f\"âš ï¸ Modelo nÃ£o suporta anÃ¡lise de importÃ¢ncia nativa\")\n",
    "    \n",
    "    # Usar importÃ¢ncia por permutaÃ§Ã£o\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    print(\"Calculando importÃ¢ncia por permutaÃ§Ã£o...\")\n",
    "    perm_importance = permutation_importance(\n",
    "        final_model, X_test_scaled, y_test, \n",
    "        n_repeats=5, random_state=RANDOM_STATE, \n",
    "        scoring='f1'\n",
    "    )\n",
    "    \n",
    "    df_perm_importance = pd.DataFrame({\n",
    "        'feature': X_train_final.columns.tolist(),\n",
    "        'importance_mean': perm_importance.importances_mean,\n",
    "        'importance_std': perm_importance.importances_std\n",
    "    }).sort_values('importance_mean', ascending=False)\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP 15 FEATURES (IMPORTÃ‚NCIA POR PERMUTAÃ‡ÃƒO):\")\n",
    "    for i, (_, row) in enumerate(df_perm_importance.head(15).iterrows(), 1):\n",
    "        print(f\"   {i:2d}Âº {row['feature']}: {row['importance_mean']:.4f} (Â±{row['importance_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5554ce",
   "metadata": {},
   "source": [
    "## 10. ConclusÃµes e RelatÃ³rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95544fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RelatÃ³rio final do projeto\n",
    "print(\"ğŸ“‹ RELATÃ“RIO FINAL DO PROJETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Resumo executivo\n",
    "print(\"ğŸ¯ RESUMO EXECUTIVO:\")\n",
    "print(f\"   â€¢ Problema: PrediÃ§Ã£o de aprovaÃ§Ã£o no processo seletivo PUC-Rio\")\n",
    "print(f\"   â€¢ Tipo: ClassificaÃ§Ã£o binÃ¡ria supervisionada\")\n",
    "print(f\"   â€¢ Dataset: {len(df_clean)} candidatos com {len(X.columns)} features\")\n",
    "print(f\"   â€¢ Melhor modelo: {type(final_model).__name__}\")\n",
    "print(f\"   â€¢ Performance final: F1-Score = {test_f1:.4f}\")\n",
    "\n",
    "# Recursos computacionais\n",
    "print(f\"\\nğŸ“Š RECURSOS COMPUTACIONAIS:\")\n",
    "print(f\"   â€¢ Tempo de treinamento: {final_train_time:.2f} segundos\")\n",
    "print(f\"   â€¢ MemÃ³ria dos dados: ~{df_clean.memory_usage(deep=True).sum() / (1024**2):.1f} MB\")\n",
    "\n",
    "# Melhoria sobre baseline\n",
    "improvement = ((test_f1 - baseline_threshold) / baseline_threshold) * 100\n",
    "print(f\"\\nğŸ“ˆ MELHORIA SOBRE BASELINE:\")\n",
    "print(f\"   â€¢ Baseline F1-Score: {baseline_threshold:.4f}\")\n",
    "print(f\"   â€¢ Modelo final F1-Score: {test_f1:.4f}\")\n",
    "print(f\"   â€¢ Melhoria: {improvement:+.1f}%\")\n",
    "\n",
    "# AnÃ¡lise de overfitting\n",
    "print(f\"\\nğŸ” ANÃLISE DE OVERFITTING:\")\n",
    "print(f\"   â€¢ Gap de generalizaÃ§Ã£o: {generalization_gap:.4f}\")\n",
    "if abs(generalization_gap) < 0.02:\n",
    "    overfitting_status = \"NÃ£o detectado - Excelente generalizaÃ§Ã£o\"\n",
    "elif abs(generalization_gap) < 0.05:\n",
    "    overfitting_status = \"Leve - GeneralizaÃ§Ã£o aceitÃ¡vel\"\n",
    "else:\n",
    "    overfitting_status = \"Detectado - Requer atenÃ§Ã£o\"\n",
    "print(f\"   â€¢ Status: {overfitting_status}\")\n",
    "\n",
    "# LimitaÃ§Ãµes\n",
    "print(f\"\\nâš ï¸ LIMITAÃ‡Ã•ES IDENTIFICADAS:\")\n",
    "print(f\"   1. Dataset sintÃ©tico (nÃ£o reflete complexidade real)\")\n",
    "print(f\"   2. Tamanho limitado do dataset ({len(df_clean)} amostras)\")\n",
    "print(f\"   3. Features podem nÃ£o capturar todos os critÃ©rios de seleÃ§Ã£o\")\n",
    "print(f\"   4. Aspectos subjetivos da entrevista nÃ£o modelados\")\n",
    "\n",
    "# SugestÃµes de melhorias\n",
    "print(f\"\\nğŸš€ SUGESTÃ•ES DE MELHORIAS:\")\n",
    "print(f\"   1. Coleta de dados reais de processos seletivos\")\n",
    "print(f\"   2. InclusÃ£o de features textuais (cartas de motivaÃ§Ã£o)\")\n",
    "print(f\"   3. ImplementaÃ§Ã£o de explicabilidade (SHAP, LIME)\")\n",
    "print(f\"   4. Monitoramento de viÃ©s e equidade\")\n",
    "print(f\"   5. Ensemble de mÃºltiplos modelos\")\n",
    "\n",
    "# InterpretaÃ§Ã£o final\n",
    "print(f\"\\nğŸ“ APLICAÃ‡ÃƒO PRÃTICA:\")\n",
    "print(f\"   â€¢ Ferramenta de apoio para triagem inicial\")\n",
    "print(f\"   â€¢ IdentificaÃ§Ã£o de perfis promissores\")\n",
    "print(f\"   â€¢ Deve complementar, nÃ£o substituir, avaliaÃ§Ã£o humana\")\n",
    "print(f\"   â€¢ NecessÃ¡ria validaÃ§Ã£o com comissÃ£o de seleÃ§Ã£o\")\n",
    "\n",
    "print(f\"\\nâœ… Projeto concluÃ­do com sucesso!\")\n",
    "print(f\"ğŸ“ Modelo pronto para apresentaÃ§Ã£o e discussÃ£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01637f74",
   "metadata": {},
   "source": [
    "### ğŸ“ **ConclusÃ£o: De Dados Brutos a Insights AcionÃ¡veis**\n",
    "\n",
    "**AÃ§Ã£o!** Acabamos de completar a transformaÃ§Ã£o 2000 perfis de candidatos em um sistema inteligente capaz de predizer aprovaÃ§Ãµes acadÃªmicas.\n",
    "\n",
    "**ğŸ“š O que foi feito - Passo a Passo:**\n",
    "\n",
    "**ğŸ Passo 1**: PreparaÃ§Ã£o do ambiente - Importamos ferramentas e definimos o problema\n",
    "**ğŸ“Š Passo 2**: Conhecendo nosso modelo - Carregamos e exploramos 2000 candidatos\n",
    "**ğŸ§¹ Passo 3**: Limpeza e OrganizaÃ§Ã£o - Preparamos dados para anÃ¡lise\n",
    "**âš™ï¸ Passo 4**: Engenharia Criativa - Criamos novas features inteligentes\n",
    "**ğŸ”¢ Passo 5**: Converter - Convertemos categorias para linguagem ML\n",
    "**ğŸ“Š Passo 6**: Dividir para conquistar - Dividimos dados para treino/validaÃ§Ã£o/teste\n",
    "**ğŸ Passo 7**: Baselines - Estabelecemos padrÃµes mÃ­nimos\n",
    "**ğŸ¤– Passo 8**: ExecuÃ§Ã£o dos 7 Algoritmos - Testamos diferentes abordagens ML\n",
    "**ğŸ›ï¸ Passo 9**: OtimizaÃ§Ã£o - Fine-tuning para mÃ¡xima performance\n",
    "**ğŸ† Passo 10**: teste - Teste final em dados limpos\n",
    "**ğŸ” Passo 11**: ConclusÃµes - AnÃ¡lise de importÃ¢ncia de features\n",
    "\n",
    "**ğŸ¯ Conquistas AlcanÃ§adas:**\n",
    "- âœ… **Modelo Funcional**: F1-Score competitivo para o problema\n",
    "- âœ… **Pipeline Completo**: Do raw data ao modelo em produÃ§Ã£o\n",
    "- âœ… **Metodologia CientÃ­fica**: ValidaÃ§Ã£o cruzada e teste independente\n",
    "- âœ… **Interpretabilidade**: Sabemos POR QUE o modelo decide\n",
    "- âœ… **Reprodutibilidade**: Qualquer pessoa pode replicar nossos resultados\n",
    "- âœ… **DocumentaÃ§Ã£o Rica**: Cada etapa explicada e justificada\n",
    "\n",
    "**ğŸš€ Impacto e AplicaÃ§Ã£o PrÃ¡tica:**\n",
    "Nosso modelo nÃ£o Ã© apenas nÃºmeros - Ã© uma **ferramenta de apoio Ã  decisÃ£o** que pode:\n",
    "- Acelerar triagem inicial de candidatos\n",
    "- Identificar perfis promissores sistematicamente\n",
    "- Reduzir viÃ©s humano em avaliaÃ§Ãµes\n",
    "- Fornecer critÃ©rios objetivos e auditÃ¡veis\n",
    "\n",
    "**ğŸ§  LiÃ§Ãµes Aprendidas:**\n",
    "1. **Dados de qualidade > algoritmos complexos**\n",
    "2. **ValidaÃ§Ã£o rigorosa > performance pontual**\n",
    "3. **Interpretabilidade > precisÃ£o absoluta**\n",
    "4. **Metodologia > resultados isolados**\n",
    "\n",
    "**ğŸŠ ConclusÃ£o Final:**\n",
    "Transformamos dados atravÃ©s do carregamento de um dataset em conhecimento, dados em insights, e cÃ³digo em impacto real. Esta Ã© a essÃªncia da CiÃªncia de Dados - usar matemÃ¡tica e programaÃ§Ã£o para resolver problemas humanos reais!\n",
    "\n",
    "**ğŸŒŸ \"Data Science is not magic - it's methodology, persistence, and a little bit of curiosity about the patterns that shape our world.\"**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
